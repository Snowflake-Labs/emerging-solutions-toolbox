{
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "lastEditStatus": {
   "authorEmail": "kirk.mason@snowflake.com",
   "authorId": "330147619279",
   "authorName": "KMASON",
   "lastEditTime": 1742872969761,
   "notebookId": "exgz3t47rgulreu6w3xw",
   "sessionId": "0af6eae7-10ee-4dec-a2a5-38429cd55fb0"
  }
 },
 "nbformat_minor": 2,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000000",
   "metadata": {
    "collapsed": false,
    "name": "md_title"
   },
   "source": [
    "# Inference Notebook\n",
    "Use the model trained in the modeling notebook to make predictions on an inference dataset.\n",
    "\n",
    "#### NOTE: The user must have an inference dataset available as a table or view in Snowflake before running this notebook.\n",
    "- If using a __direct multi-step forecasting__ pattern, the inference dataset does not need to contain records for the future datetime points.\n",
    "- If using a __global modeling__ pattern, the inference dataset must contain records for each future datetime to be forecasted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000001",
   "metadata": {
    "name": "md_instructions"
   },
   "source": [
    "❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ \n",
    "## Instructions\n",
    "\n",
    "1. Go to the ____set_global_variables___ cell in the __SETUP__ section below. \n",
    "    - Adjust the values of the user constants\n",
    "2. Click ___Run all___ in the upper right corner of the notebook to run the entire notebook. \n",
    "    - The notebook will perform feature engineering steps and inference. Predictions will be stored in a Snowflake table.\n",
    "    \n",
    "❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce110000-1111-2222-3333-ffffff000002",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "_imports"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "from snowflake.ml.registry import registry\n",
    "from snowflake.snowpark import Window\n",
    "from snowflake.snowpark import functions as F\n",
    "from snowflake.snowpark import types as T\n",
    "\n",
    "from forecast_model_builder.feature_engineering import (\n",
    "    apply_functions_in_a_loop,\n",
    "    expand_datetime,\n",
    "    recent_rolling_avg,\n",
    "    roll_up,\n",
    "    verify_current_frequency,\n",
    "    verify_valid_rollup_spec,\n",
    ")\n",
    "from forecast_model_builder.utils import connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce110000-1111-2222-3333-ffffff000003",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "_establish_session"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session db.schema: KMASON.PUBLIC\n",
      "Session warehouse: WH_XS\n",
      "Current Datetime: 2025-03-05 20:05:06.782144\n"
     ]
    }
   ],
   "source": [
    "# Establish session\n",
    "session = connect(connection_name=\"default\")\n",
    "session_db = session.connection.database\n",
    "session_schema = session.connection.schema\n",
    "session_wh = session.connection.warehouse\n",
    "print(f\"Session db.schema: {session_db}.{session_schema}\")\n",
    "print(f\"Session warehouse: {session_wh}\")\n",
    "\n",
    "# Query tag\n",
    "query_tag = '{\"origin\":\"sf_sit\", \"name\":\"sit_forecasting\", \"version\":{\"major\":1, \"minor\":0}, \"attributes\":{\"component\":\"inference\"}}'\n",
    "session.query_tag = query_tag\n",
    "\n",
    "# Get the current datetime  (This will be saved in the model storage table)\n",
    "run_dttm = datetime.now()\n",
    "print(f\"Current Datetime: {run_dttm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000004",
   "metadata": {
    "collapsed": false,
    "name": "md_USER_SETUP"
   },
   "source": [
    "-----\n",
    "# SETUP\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000005",
   "metadata": {
    "language": "python",
    "name": "_set_global_variables"
   },
   "outputs": [],
   "source": [
    "# Establish cutoff datetime for the records that will be scored using the forecast model.\n",
    "# NOTE: For Direct Multi-Step Forecasting, this value will likely be the most recent date, since this pattern does not take in records for future dates as input.\n",
    "#       For Global Modeling, this value will be the first future datetime value in the records that will be scored.\n",
    "# NOTE: This cutoff will be applied AFTER feature engineering, so that lag features can be calculated.\n",
    "INFERENCE_START_TIMESTAMP = \"2025-01-01 00:00:00.000\"\n",
    "\n",
    "# Table name to store the PREDICTION results.\n",
    "# NOTE: If the table name is not fully qualified with DB.SCHEMA, the session's default database and schema will be used.\n",
    "# NOTE: Currently the code will overwrite the existing predictions table with the predictions from this run.\n",
    "INFERENCE_RESULT_TBL_NM = \"FORECAST_RESULTS\"\n",
    "\n",
    "# Input data for inference\n",
    "INFERENCE_DB = \"FORECAST_MODEL_BUILDER\"\n",
    "INFERENCE_SCHEMA = \"BASE\"\n",
    "INFERENCE_TABLE_NM = \"DAILY_PARTITIONED_SAMPLE_DATA\"\n",
    "\n",
    "# Name of the model to use for inference, as well as the Database and Schema of the model registry.\n",
    "# NOTE: The default model version from the registry will be used.\n",
    "MODEL_DB = \"FORECAST_MODEL_BUILDER\"\n",
    "MODEL_SCHEMA = \"MODELING\"\n",
    "MODEL_NAME = \"TEST_MODEL_1\"\n",
    "\n",
    "# Scaling up the warehouse may speed up execution time, especially if there are many partitions.\n",
    "# NOTE: If set to None, then the session warehouse will be used.\n",
    "INFERENCE_WH = \"STANDARD_XL\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000006",
   "metadata": {
    "name": "md_objects"
   },
   "source": [
    "-----\n",
    "# Establish objects needed for this run\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce110000-1111-2222-3333-ffffff000007",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "_set_other_objects"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session warehouse:          WH_XS\n",
      "Inference warehouse:        STANDARD_XL \n",
      "\n",
      "Model Version:              TRICKY_FALCON_4\n",
      "Modeling Frequency:         day\n",
      "Train Separate Lead Models: False\n"
     ]
    }
   ],
   "source": [
    "# Derived Objects\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "# Notebook Warehouse\n",
    "# -----------------------------------------------------------------------\n",
    "SESSION_WH = session.connection.warehouse\n",
    "print(f\"Session warehouse:          {SESSION_WH}\")\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "# Check Inference Warehouse\n",
    "# -----------------------------------------------------------------------\n",
    "# Check that the user specified an available warehouse as INFERENCE_WH. If not, use the session warehouse.\n",
    "available_warehouses = [\n",
    "    row[\"NAME\"]\n",
    "    for row in session.sql(\"SHOW WAREHOUSES\")\n",
    "    .select(F.col('\"name\"').alias(\"NAME\"))\n",
    "    .collect()\n",
    "]\n",
    "\n",
    "if INFERENCE_WH in available_warehouses:\n",
    "    print(f\"Inference warehouse:        {INFERENCE_WH} \\n\")\n",
    "else:\n",
    "    print(\n",
    "        f\"WARNING: User does not have access to INFERENCE_WH = '{INFERENCE_WH}'. Inference will use '{SESSION_WH}' instead. \\n\"\n",
    "    )\n",
    "    INFERENCE_WH = SESSION_WH\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "# Fully qualified MODEL NAME\n",
    "# -----------------------------------------------------------------------\n",
    "qualified_model_name = f\"{MODEL_DB}.{MODEL_SCHEMA}.{MODEL_NAME}\"\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "# Get the model and the version name of the default version\n",
    "# -----------------------------------------------------------------------\n",
    "# Establish registry object\n",
    "reg = registry.Registry(\n",
    "    session=session, database_name=MODEL_DB, schema_name=MODEL_SCHEMA\n",
    ")\n",
    "\n",
    "# Get the model from the registry\n",
    "mv = reg.get_model(qualified_model_name).default\n",
    "\n",
    "# Get the default version name\n",
    "model_version_nm = mv.version_name\n",
    "\n",
    "print(f\"Model Version:              {model_version_nm}\")\n",
    "\n",
    "# --------------------------------\n",
    "# User Constants from Model Setup\n",
    "# --------------------------------\n",
    "stored_constants = mv.show_metrics()[\"user_settings\"]\n",
    "\n",
    "TIME_PERIOD_COLUMN = stored_constants[\"TIME_PERIOD_COLUMN\"]\n",
    "TARGET_COLUMN = stored_constants[\"TARGET_COLUMN\"]\n",
    "PARTITION_COLUMNS = stored_constants[\"PARTITION_COLUMNS\"]\n",
    "EXOGENOUS_COLUMNS = stored_constants[\"EXOGENOUS_COLUMNS\"]\n",
    "ALL_EXOG_COLS_HAVE_FUTURE_VALS = stored_constants[\"ALL_EXOG_COLS_HAVE_FUTURE_VALS\"]\n",
    "CREATE_LAG_FEATURE = stored_constants[\"CREATE_LAG_FEATURE\"]\n",
    "CURRENT_FREQUENCY = stored_constants[\"CURRENT_FREQUENCY\"]\n",
    "ROLLUP_FREQUENCY = stored_constants[\"ROLLUP_FREQUENCY\"]\n",
    "ROLLUP_AGGREGATIONS = stored_constants[\"ROLLUP_AGGREGATIONS\"]\n",
    "FORECAST_HORIZON = stored_constants[\"FORECAST_HORIZON\"]\n",
    "INFERENCE_APPROX_BATCH_SIZE = stored_constants[\"INFERENCE_APPROX_BATCH_SIZE\"]\n",
    "MODEL_BINARY_STORAGE_TBL_NM = stored_constants[\"MODEL_BINARY_STORAGE_TBL_NM\"]\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "# Create a window spec\n",
    "# -----------------------------------------------------------------------\n",
    "window_spec = Window.partitionBy(PARTITION_COLUMNS).orderBy(TIME_PERIOD_COLUMN)\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "# Create a variable to hold the granularity at which we will be modeling\n",
    "# -----------------------------------------------------------------------\n",
    "CURRENT_FREQUENCY = CURRENT_FREQUENCY.lower()\n",
    "\n",
    "if ROLLUP_FREQUENCY is not None:\n",
    "    ROLLUP_FREQUENCY = ROLLUP_FREQUENCY.lower()\n",
    "    if ROLLUP_FREQUENCY.lower() == \"none\":\n",
    "        ROLLUP_FREQUENCY = None\n",
    "\n",
    "modeling_frequency = CURRENT_FREQUENCY if ROLLUP_FREQUENCY is None else ROLLUP_FREQUENCY\n",
    "print(f\"Modeling Frequency:         {modeling_frequency}\")\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "# Establish modeling pattern\n",
    "# -----------------------------------------------------------------------\n",
    "# Either (1) train_separate_lead_models = False : all features have future values in the inference data, so we don't need a separate model for each lead\n",
    "# or (2) train_separate_lead_models = True : data contains exogenous variables that the inference data won't have future values for, requiring lead modeling\n",
    "train_separate_lead_models = (\n",
    "    False\n",
    "    if ALL_EXOG_COLS_HAVE_FUTURE_VALS is True or len(EXOGENOUS_COLUMNS) == 0\n",
    "    else True\n",
    ")\n",
    "print(f\"Train Separate Lead Models: {train_separate_lead_models}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b62a21a-0509-419b-a37b-fe73319fafe0",
   "metadata": {
    "collapsed": false,
    "name": "md_establish_df"
   },
   "source": [
    "# Establish DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000008",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "_base_dataset"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference set size: 367500\n",
      "First time period in inference set: 2021-01-01 00:00:00\n",
      "Last time period in inference set:  2025-01-09 00:00:00\n",
      "Total Partition Count: 250\n",
      "-----------------------------------------------------------------------------------------\n",
      "|\"ORDER_TIMESTAMP\"    |\"TARGET\"           |\"STORE_ID\"  |\"PRODUCT_ID\"  |\"FEATURE_1\"      |\n",
      "-----------------------------------------------------------------------------------------\n",
      "|2022-05-14 00:00:00  |306.2132575120000  |22          |8             |320.12911991500  |\n",
      "|2022-05-15 00:00:00  |325.2240795290000  |22          |8             |452.84631991700  |\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Snowpark DataFrame from table in Snowflake\n",
    "sdf = session.table(f\"{INFERENCE_DB}.{INFERENCE_SCHEMA}.{INFERENCE_TABLE_NM}\")\n",
    "\n",
    "# If the inference dataset does not have the TARGET column already, add it and fill it with null values\n",
    "if TARGET_COLUMN not in sdf.columns:\n",
    "    sdf = sdf.with_column(TARGET_COLUMN, F.lit(None).cast(T.FloatType()))\n",
    "\n",
    "# Only keep the columns specified in the config\n",
    "sdf = sdf.select(\n",
    "    TIME_PERIOD_COLUMN, TARGET_COLUMN, *PARTITION_COLUMNS, *EXOGENOUS_COLUMNS\n",
    ")\n",
    "\n",
    "# Inspect the data\n",
    "dttm_boundaries = sdf.select(\n",
    "    F.min(TIME_PERIOD_COLUMN).alias(\"MIN_DTTM\"),\n",
    "    F.max(TIME_PERIOD_COLUMN).alias(\"MAX_DTTM\"),\n",
    ").collect()[0]\n",
    "print(f\"Inference set size: {sdf.count()}\")\n",
    "print(f\"First time period in inference set: {dttm_boundaries['MIN_DTTM']}\")\n",
    "print(f\"Last time period in inference set:  {dttm_boundaries['MAX_DTTM']}\")\n",
    "if len(PARTITION_COLUMNS) > 0:\n",
    "    print(f\"Total Partition Count: {sdf.select(PARTITION_COLUMNS).distinct().count()}\")\n",
    "else:\n",
    "    print(\"No partition columns specified.\")\n",
    "sdf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce110000-1111-2222-3333-ffffff000009",
   "metadata": {
    "language": "python",
    "name": "_prelim_checks"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common time between consecutive records (frequency): 1.0 day(s)\n",
      "    The current frequency appears to be in DAY granularity.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------\n",
    "# Preliminary checks\n",
    "# -----------------------------------------\n",
    "# Verify valid rollup specification.\n",
    "# Raise an error if the user specifies a rollup frequency that is finer grain than the current frequency\n",
    "# Raise an error if the user does not specify a rollup aggregation for the target and all exogenous columns\n",
    "verify_valid_rollup_spec(\n",
    "    CURRENT_FREQUENCY, ROLLUP_FREQUENCY, ROLLUP_AGGREGATIONS, EXOGENOUS_COLUMNS\n",
    ")\n",
    "\n",
    "# Roughly verify the current frequency (datetime difference between consecutive records) of the time series data\n",
    "verify_current_frequency(sdf, TIME_PERIOD_COLUMN, window_spec, CURRENT_FREQUENCY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000010",
   "metadata": {
    "name": "md_feature_engineering"
   },
   "source": [
    "-----\n",
    "# Feature Engineering\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce110000-1111-2222-3333-ffffff000011",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "_feature_engineering"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total record count after rolling up:   367500\n",
      "Total record count of final data:      367500\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"ORDER_TIMESTAMP\"    |\"TARGET\"       |\"FEATURE_1\"    |\"YEAR\"  |\"MONTH_SIN\"         |\"MONTH_COS\"          |\"WEEK_OF_YEAR_SIN\"  |\"WEEK_OF_YEAR_COS\"   |\"DAY_OF_WEEK_SUN\"  |\"DAY_OF_WEEK_MON\"  |\"DAY_OF_WEEK_TUE\"  |\"DAY_OF_WEEK_WED\"  |\"DAY_OF_WEEK_THU\"  |\"DAY_OF_WEEK_FRI\"  |\"DAY_OF_WEEK_SAT\"  |\"DAY_OF_YEAR_SIN\"   |\"DAY_OF_YEAR_COS\"    |\"DAYS_SINCE_JAN2020\"  |\"MODEL_TARGET\"  |\"GROUP_IDENTIFIER\"  |\"GROUP_IDENTIFIER_STRING\"  |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|2022-05-14 00:00:00  |306.213257512  |320.129119915  |2022    |0.5000000000000003  |-0.8660254037844385  |0.748510748171101   |-0.6631226582407953  |0                  |0                  |0                  |0                  |0                  |0                  |1                  |0.7412220108485956  |-0.6712599575675317  |864                   |306.213257512   |{                   |STORE_ID_22_PRODUCT_ID_8   |\n",
      "|                     |               |               |        |                    |                     |                    |                     |                   |                   |                   |                   |                   |                   |                   |                    |                     |                      |                |  \"PRODUCT_ID\": 8,  |                           |\n",
      "|                     |               |               |        |                    |                     |                    |                     |                   |                   |                   |                   |                   |                   |                   |                    |                     |                      |                |  \"STORE_ID\": 22    |                           |\n",
      "|                     |               |               |        |                    |                     |                    |                     |                   |                   |                   |                   |                   |                   |                   |                    |                     |                      |                |}                   |                           |\n",
      "|2022-05-15 00:00:00  |325.224079529  |452.846319917  |2022    |0.5000000000000003  |-0.8660254037844385  |0.748510748171101   |-0.6631226582407953  |1                  |0                  |0                  |0                  |0                  |0                  |0                  |0.7295575540864875  |-0.6839194216246106  |865                   |325.224079529   |{                   |STORE_ID_22_PRODUCT_ID_8   |\n",
      "|                     |               |               |        |                    |                     |                    |                     |                   |                   |                   |                   |                   |                   |                   |                    |                     |                      |                |  \"PRODUCT_ID\": 8,  |                           |\n",
      "|                     |               |               |        |                    |                     |                    |                     |                   |                   |                   |                   |                   |                   |                   |                    |                     |                      |                |  \"STORE_ID\": 22    |                           |\n",
      "|                     |               |               |        |                    |                     |                    |                     |                   |                   |                   |                   |                   |                   |                   |                    |                     |                      |                |}                   |                           |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First Convert Decimal data types to Floats (because DecimalType doesn't work in modeling algorithms)\n",
    "sdf_converted = sdf.select(\n",
    "    [\n",
    "        F.col(field.name).cast(T.FloatType()).alias(field.name)\n",
    "        if isinstance(field.datatype, T.DecimalType)\n",
    "        else F.col(field.name)\n",
    "        for field in sdf.schema\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# ROLL UP to specified granularity\n",
    "# ------------------------------------------------------------------------\n",
    "sdf_rollup = roll_up(\n",
    "    sdf_converted,\n",
    "    TIME_PERIOD_COLUMN,\n",
    "    PARTITION_COLUMNS,\n",
    "    TARGET_COLUMN,\n",
    "    EXOGENOUS_COLUMNS,\n",
    "    ROLLUP_FREQUENCY,\n",
    "    ROLLUP_AGGREGATIONS,\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# Create time-derived features\n",
    "# ------------------------------------------------------------------------\n",
    "sdf_engineered = expand_datetime(sdf_rollup, TIME_PERIOD_COLUMN, modeling_frequency)\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# Create rolling average of most recent time periods\n",
    "# ------------------------------------------------------------------------\n",
    "# NOTE: We can only generate recent rolling average features if we are training separate lead models.\n",
    "if CREATE_LAG_FEATURE & train_separate_lead_models:\n",
    "    sdf_engineered = recent_rolling_avg(\n",
    "        sdf_engineered, [TARGET_COLUMN], window_spec, modeling_frequency\n",
    "    )\n",
    "\n",
    "# Cached Results\n",
    "sdf_engineered = sdf_engineered.cache_result()\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# Create LAG features (and possibly LEAD feature) of the TARGET variable\n",
    "# ------------------------------------------------------------------------\n",
    "final_sdf = apply_functions_in_a_loop(\n",
    "    train_separate_lead_models=train_separate_lead_models,\n",
    "    partition_column_list=PARTITION_COLUMNS,\n",
    "    input_sdf=sdf_engineered,\n",
    "    target_column=TARGET_COLUMN,\n",
    "    time_step_frequency=modeling_frequency,\n",
    "    forecast_horizon=FORECAST_HORIZON,\n",
    "    w_spec=window_spec,\n",
    "    create_lag_feature=CREATE_LAG_FEATURE,\n",
    ")\n",
    "\n",
    "# Cache the final SDF\n",
    "final_sdf = final_sdf.cache_result()\n",
    "\n",
    "# Inspect data\n",
    "print(f\"Total record count after rolling up:   {sdf_rollup.count()}\")\n",
    "print(f\"Total record count of final data:      {final_sdf.count()}\")\n",
    "final_sdf.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000012",
   "metadata": {
    "name": "md_inference"
   },
   "source": [
    "-----\n",
    "# Inference\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce110000-1111-2222-3333-ffffff000013",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "_perform_inference"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference input data row count: 2250\n",
      "Number of end partition invocations to expect in the query profile: 250\n",
      "Predictions\n",
      "-----------------------------------------------------------------------\n",
      "|\"_PRED_\"           |\"GROUP_IDENTIFIER_STRING\"  |\"ORDER_TIMESTAMP\"    |\n",
      "-----------------------------------------------------------------------\n",
      "|681.7679443359375  |STORE_ID_20_PRODUCT_ID_3   |2025-01-01 00:00:00  |\n",
      "|678.8994140625     |STORE_ID_20_PRODUCT_ID_3   |2025-01-02 00:00:00  |\n",
      "-----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# INFERENCE\n",
    "# ------------------------------------------------------------------------\n",
    "# Prep data set for inference\n",
    "inference_input_df = final_sdf.filter(\n",
    "    F.col(TIME_PERIOD_COLUMN) >= INFERENCE_START_TIMESTAMP\n",
    ").drop(\"GROUP_IDENTIFIER\")\n",
    "\n",
    "model_bytes_table = (\n",
    "    session.table(MODEL_BINARY_STORAGE_TBL_NM)\n",
    "    .filter(F.col(\"MODEL_NAME\") == MODEL_NAME)\n",
    "    .filter(F.col(\"MODEL_VERSION\") == model_version_nm)\n",
    "    .select(\"GROUP_IDENTIFIER_STRING\", \"MODEL_BINARY\")\n",
    ")\n",
    "\n",
    "# NOTE: We inner joint to the model bytes table to ensure that we only try run inference on partitions that have a model.\n",
    "inference_input_df = inference_input_df.join(\n",
    "    model_bytes_table, on=[\"GROUP_IDENTIFIER_STRING\"], how=\"inner\"\n",
    ")\n",
    "\n",
    "# Add a column called BATCH_GROUP,\n",
    "#   which has the property that for each unique value there are roughly the number of records specified in batch_size.\n",
    "# Use that to create a PARTITION_ID column that will be used to run inference in batches.\n",
    "# We do this to avoid running out of memory when performing inference on a large number of records.\n",
    "largest_partition_record_count = (\n",
    "    inference_input_df.group_by(\"GROUP_IDENTIFIER_STRING\")\n",
    "    .agg(F.count(\"*\").alias(\"PARTITION_RECORD_COUNT\"))\n",
    "    .agg(F.max(\"PARTITION_RECORD_COUNT\").alias(\"MAX_PARTITION_RECORD_COUNT\"))\n",
    "    .collect()[0][\"MAX_PARTITION_RECORD_COUNT\"]\n",
    ")\n",
    "batch_size = INFERENCE_APPROX_BATCH_SIZE\n",
    "number_of_batches = math.ceil(largest_partition_record_count / batch_size)\n",
    "inference_input_df = (\n",
    "    inference_input_df.with_column(\n",
    "        \"BATCH_GROUP\", F.abs(F.random(123)) % F.lit(number_of_batches)\n",
    "    )\n",
    "    .with_column(\n",
    "        \"PARTITION_ID\",\n",
    "        F.concat_ws(\n",
    "            F.lit(\"__\"), F.col(\"GROUP_IDENTIFIER_STRING\"), F.col(\"BATCH_GROUP\")\n",
    "        ),\n",
    "    )\n",
    "    .drop(\"RANDOM_NUMBER\", \"BATCH_GROUP\")\n",
    ")\n",
    "\n",
    "# Look at a couple rows of the inference input data\n",
    "print(f\"Inference input data row count: {inference_input_df.count()}\")\n",
    "print(\n",
    "    f\"Number of end partition invocations to expect in the query profile: {inference_input_df.select('PARTITION_ID').distinct().count()}\"\n",
    ")\n",
    "\n",
    "# Perform inference from the model registry\n",
    "session.use_warehouse(INFERENCE_WH)\n",
    "\n",
    "# Use the model to score the input data\n",
    "inference_result = mv.run(inference_input_df, partition_column=\"PARTITION_ID\").select(\n",
    "    \"_PRED_\",\n",
    "    F.col(\"GROUP_IDENTIFIER_STRING_OUT_\").alias(\"GROUP_IDENTIFIER_STRING\"),\n",
    "    F.col(f\"{TIME_PERIOD_COLUMN}_OUT_\").alias(TIME_PERIOD_COLUMN),\n",
    ")\n",
    "\n",
    "print(\"Predictions\")\n",
    "inference_result.show(2)\n",
    "session.use_warehouse(SESSION_WH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000014",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "_write_predictions_to_table"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions written to table: FORECAST_RESULTS\n"
     ]
    }
   ],
   "source": [
    "# Write predictions to a Snowflake table.\n",
    "# Right now this is set up to overwrite the table if it already exists.\n",
    "inference_result.write.save_as_table(INFERENCE_RESULT_TBL_NM, mode=\"overwrite\")\n",
    "print(\n",
    "    f\"Predictions written to table: {session_db}.{session_schema}.{INFERENCE_RESULT_TBL_NM}\"\n",
    ")\n",
    "\n",
    "# Look at a few rows of the snowflake table\n",
    "print(\"Sample records:\")\n",
    "session.table(INFERENCE_RESULT_TBL_NM).limit(3)"
   ]
  }
 ]
}
