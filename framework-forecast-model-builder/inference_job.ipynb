{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c355754d-807d-4956-9bd1-ad553d8ac122",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "md_title"
      },
      "source": [
        "# Batch Inference Job\n",
        "\n",
        "This notebook is designed to be scheduled as a recurring job within Snowflake to perform batch inference using a trained forecasting model. It reads from the Feature Store, applies the model registered in the Model Registry, and appends predictions to a results table.\n",
        "\n",
        "The notebook tracks which predictions have already been made and only generates new predictions for time periods that haven't been processed yet."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cba0b12-4e6b-4510-b974-21b2056b9057",
      "metadata": {
        "codeCollapsed": true,
        "name": "md_instructions"
      },
      "source": [
        "❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ \n",
        "\n",
        "__Prerequisites before running this notebook:__ \n",
        "\n",
        "- A model must have been trained and saved to the Model Registry using the **modeling.ipynb** notebook.\n",
        "- The model should have been evaluated using the **evaluation.ipynb** notebook to ensure prediction quality.\n",
        "- The Feature Store and Feature View must be set up and accessible.\n",
        "\n",
        "## Instructions\n",
        "\n",
        "1. Go to the ___VARS___ cell in the __SETUP__ section below. \n",
        "    - Adjust the values of the user constants to match your deployment requirements.\n",
        "    - Key settings include the model name, inference warehouse, and task schedule.\n",
        "2. Click ___Run all___ to execute the notebook manually, or schedule it as a Snowflake Notebook Task for recurring batch inference.\n",
        "    - The notebook will automatically detect new time periods requiring predictions.\n",
        "    - Predictions are appended to the results table, avoiding duplicate processing.\n",
        "    \n",
        "❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f0d158f-3d3c-46e7-ae7d-1018e7483134",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "language": "python",
        "name": "_imports"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from forecast_model_builder.utils import connect, perform_inference\n",
        "from snowflake.ml.registry import registry\n",
        "from snowflake.ml.feature_store import FeatureStore, CreationMode\n",
        "import snowflake.snowpark.functions as F"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b1a2186-ad23-4195-b5cc-19a094a6d2c0",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "md_setup"
      },
      "source": [
        "-----\n",
        "# SETUP\n",
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d22e1b3-3ff1-4bef-b802-80ce72237fca",
      "metadata": {
        "codeCollapsed": false,
        "collapsed": false,
        "language": "python",
        "name": "_set_global_variables"
      },
      "outputs": [],
      "source": [
        "# SET GLOBAL VARIABLES FOR THIS JOB\n",
        "\n",
        "# Name of project\n",
        "PROJECT_SCHEMA = \"TEST_PROJECT\"\n",
        "\n",
        "# Set warehouse\n",
        "SESSION_WH = \"FORECAST_MODEL_BUILDER_WH\"\n",
        "\n",
        "# --------------------------------\n",
        "# Prediction Results Storage\n",
        "# --------------------------------\n",
        "# Table name to store the PREDICTION results.\n",
        "# NOTE: If the table name is not fully qualified with DB.SCHEMA, the session's default database and schema will be used.\n",
        "INFERENCE_RESULT_TBL_NM = \"FORECAST_RESULTS\"\n",
        "\n",
        "# --------------------------------\n",
        "# Model Configuration\n",
        "# --------------------------------\n",
        "# Name of the model to use for inference, as well as the Database and Schema of the model registry.\n",
        "# NOTE: The default model version from the registry will be used.\n",
        "MODEL_DB = \"FORECAST_MODEL_BUILDER\"\n",
        "MODEL_SCHEMA = \"MODELING\"\n",
        "MODEL_NAME = \"TEST_MODEL_1\"\n",
        "\n",
        "# --------------------------------\n",
        "# Virtual Warehouse\n",
        "# --------------------------------\n",
        "# Scaling up the warehouse may speed up execution time, especially if there are many partitions.\n",
        "# NOTE: If set to None, then the session warehouse will be used.\n",
        "INFERENCE_WH = \"STANDARD_XL\"\n",
        "\n",
        "# --------------------------------\n",
        "# Scheduling Options\n",
        "# --------------------------------\n",
        "# If True, the notebook task will refresh on the same schedule as the feature view.\n",
        "# If False, you must provide a custom schedule via TASK_SCHEDULE.\n",
        "REFRESH_WITH_FEATURE_VIEW = False\n",
        "\n",
        "# Schedule for the notebook task (only used if REFRESH_WITH_FEATURE_VIEW is False).\n",
        "# Examples: \"1 day\", \"1 hour\", \"USING CRON 0 9 * * * America/Los_Angeles\"\n",
        "TASK_SCHEDULE = \"1 day\"\n",
        "\n",
        "# --------------------------------\n",
        "# Inference Date Range\n",
        "# --------------------------------\n",
        "# Inference start date - prevents processing entire history on first run.\n",
        "# Subsequent runs will automatically start from the last processed date + 1 period.\n",
        "INFERENCE_START_DATE = \"2025-01-01\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a677972b-5e3c-4cc2-8a18-2c98a851812e",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "language": "python",
        "name": "_establish_session"
      },
      "outputs": [],
      "source": [
        "# Establish session\n",
        "session = connect(connection_name=\"default\")\n",
        "session.use_database(MODEL_DB)\n",
        "session_db = MODEL_DB\n",
        "session.use_schema(PROJECT_SCHEMA)\n",
        "session_schema = PROJECT_SCHEMA\n",
        "print(f\"Session db.schema: {session_db}.{session_schema}\")\n",
        "session.use_warehouse(SESSION_WH)\n",
        "print(f\"Session warehouse: {SESSION_WH}\")\n",
        "\n",
        "# Query tag\n",
        "query_tag = '{\"origin\":\"sf_sit\", \"name\":\"sit_forecasting\", \"version\":{\"major\":1, \"minor\":0}, \"attributes\":{\"component\":\"inference\"}}'\n",
        "session.query_tag = query_tag"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08d04278-84b5-4080-b28e-1ad1852e625d",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "md_objects"
      },
      "source": [
        "-----\n",
        "# Establish Objects Needed for Inference\n",
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "856a44cd-22c1-4a1b-9000-3ce8280e8852",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "language": "python",
        "name": "_set_other_objects"
      },
      "outputs": [],
      "source": [
        "# DERIVED OBJECTS\n",
        "\n",
        "current_dttm = datetime.now()\n",
        "INFERENCE_START_DATE = datetime.strptime(INFERENCE_START_DATE, \"%Y-%m-%d\")\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "# Notebook Warehouse\n",
        "# -----------------------------------------------------------------------\n",
        "SESSION_WH = session.connection.warehouse\n",
        "print(f\"Session warehouse:          {SESSION_WH}\")\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "# Check Inference Warehouse\n",
        "# -----------------------------------------------------------------------\n",
        "# Check that the user specified an available warehouse as INFERENCE_WH. If not, use the session warehouse.\n",
        "available_warehouses = [\n",
        "    row[\"NAME\"]\n",
        "    for row in session.sql(\"SHOW WAREHOUSES\")\n",
        "    .select(F.col('\"name\"').alias(\"NAME\"))\n",
        "    .collect()\n",
        "]\n",
        "\n",
        "if INFERENCE_WH in available_warehouses:\n",
        "    print(f\"Inference warehouse:        {INFERENCE_WH} \\n\")\n",
        "else:\n",
        "    print(\n",
        "        f\"WARNING: User does not have access to INFERENCE_WH = '{INFERENCE_WH}'. Inference will use '{SESSION_WH}' instead. \\n\"\n",
        "    )\n",
        "    INFERENCE_WH = SESSION_WH\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "# Fully qualified MODEL NAME\n",
        "# -----------------------------------------------------------------------\n",
        "qualified_model_name = f\"{MODEL_DB}.{MODEL_SCHEMA}.{MODEL_NAME}\"\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "# Get the model and the version name of the default version\n",
        "# -----------------------------------------------------------------------\n",
        "# Establish registry object\n",
        "reg = registry.Registry(\n",
        "    session=session, database_name=MODEL_DB, schema_name=MODEL_SCHEMA\n",
        ")\n",
        "\n",
        "# Get the model from the registry (uses the default version)\n",
        "mv = reg.get_model(qualified_model_name).default\n",
        "\n",
        "# Get the default version name\n",
        "model_version_nm = mv.version_name\n",
        "\n",
        "print(f\"Model Version:              {model_version_nm}\")\n",
        "\n",
        "inf_table_nm = f\"{MODEL_SCHEMA}.{INFERENCE_RESULT_TBL_NM}_{MODEL_NAME}_{model_version_nm}\"\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "# Retrieve User Constants from Model Metadata\n",
        "# -----------------------------------------------------------------------\n",
        "# These settings were stored during model training and ensure consistency between training and inference.\n",
        "stored_constants = mv.show_metrics()[\"user_settings\"]\n",
        "USE_CONTEXT = stored_constants[\"USE_CONTEXT\"]\n",
        "TIME_PERIOD_COLUMN = stored_constants[\"TIME_PERIOD_COLUMN\"]\n",
        "TARGET_COLUMN = stored_constants[\"TARGET_COLUMN\"]\n",
        "ROLLUP_FREQUENCY = stored_constants[\"ROLLUP_FREQUENCY\"]\n",
        "CURRENT_FREQUENCY = stored_constants[\"CURRENT_FREQUENCY\"]\n",
        "FORECAST_HORIZON = stored_constants[\"FORECAST_HORIZON\"]\n",
        "FREQUENCY = ROLLUP_FREQUENCY if ROLLUP_FREQUENCY else CURRENT_FREQUENCY\n",
        "\n",
        "if not USE_CONTEXT:\n",
        "    MODEL_BINARY_STORAGE_TBL_NM = stored_constants[\"MODEL_BINARY_STORAGE_TBL_NM\"]\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "# Create Prediction Results Table (if not exists)\n",
        "# -----------------------------------------------------------------------\n",
        "# This table stores all inference results with metadata for tracking and auditing.\n",
        "session.sql(\n",
        "    f\"\"\"\n",
        "        create table if not exists {inf_table_nm} (\n",
        "            {TIME_PERIOD_COLUMN} TIMESTAMP,\n",
        "            GROUP_IDENTIFIER VARIANT,\n",
        "            GROUP_IDENTIFIER_STRING VARCHAR,\n",
        "            INFERENCE_DTTM TIMESTAMP,\n",
        "            PREDICTION DOUBLE\n",
        "        )\n",
        "        comment = '{query_tag}'\n",
        "    \"\"\"\n",
        ").collect()\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "# Connect to Feature Store and Get Feature View\n",
        "# -----------------------------------------------------------------------\n",
        "# The feature view is retrieved from the model's lineage to ensure the same features used\n",
        "# during training are used during inference.\n",
        "fs = FeatureStore(\n",
        "    session,\n",
        "    database=session_db,\n",
        "    name=session_schema,\n",
        "    default_warehouse=SESSION_WH,\n",
        "    creation_mode=CreationMode.FAIL_IF_NOT_EXIST,\n",
        ")\n",
        "\n",
        "fv = mv.lineage(direction='upstream')[0].lineage(direction='upstream')[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d73f32d2-47d1-4e32-874a-cbd224847a11",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "md_date_range"
      },
      "source": [
        "-----\n",
        "# Determine Inference Date Range\n",
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0f716a5-7982-4c0b-8586-50aff803b74c",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "language": "python",
        "name": "_date_range"
      },
      "outputs": [],
      "source": [
        "# -----------------------------------------------------------------------\n",
        "# Calculate Inference Date Range\n",
        "# -----------------------------------------------------------------------\n",
        "# The start date is determined by checking for existing predictions.\n",
        "# If predictions already exist for this model version, start from the last predicted date + 1 period.\n",
        "# This ensures idempotency and prevents duplicate predictions.\n",
        "\n",
        "# Get existing predictions for this model version\n",
        "result_table = session.table(inf_table_nm)\n",
        "\n",
        "# If predictions already exist, update start date to continue from where we left off\n",
        "if result_table.count() > 0:\n",
        "    INFERENCE_START_DATE = result_table.select(\n",
        "        F.dateadd(\n",
        "            FREQUENCY,\n",
        "            F.lit(1),\n",
        "            F.max(TIME_PERIOD_COLUMN)).alias(TIME_PERIOD_COLUMN)\n",
        "    ).collect()[0][TIME_PERIOD_COLUMN]\n",
        "\n",
        "# Calculate end date based on current date plus forecast horizon\n",
        "INFERENCE_END_DATE = datetime.today() + relativedelta(**{FREQUENCY + \"s\": FORECAST_HORIZON})\n",
        "\n",
        "print(f\"Inference Start Date:       {INFERENCE_START_DATE}\")\n",
        "print(f\"Inference End Date:         {INFERENCE_END_DATE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac4341b1-22e1-4cb9-bc34-f66f9ec135bd",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "md_data_filtering"
      },
      "source": [
        "-----\n",
        "# Retrieve and Filter Inference Data\n",
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0da1be7d-60fd-4d82-94d5-82a94fe62561",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "language": "python",
        "name": "_filter_data"
      },
      "outputs": [],
      "source": [
        "# -----------------------------------------------------------------------\n",
        "# Read Features from Feature View\n",
        "# -----------------------------------------------------------------------\n",
        "# Read features from the feature view and filter to the inference date range.\n",
        "sdf = fs.read_feature_view(fv).filter(\n",
        "    (F.col(TIME_PERIOD_COLUMN) >= INFERENCE_START_DATE)\n",
        "    & (F.col(TIME_PERIOD_COLUMN) < INFERENCE_END_DATE)\n",
        ")\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "# Exclude Already Predicted Records\n",
        "# -----------------------------------------------------------------------\n",
        "# Use a left anti-join to filter out any records that have already been predicted.\n",
        "# This ensures we don't create duplicate predictions if the job runs multiple times.\n",
        "#sdf = sdf.join(\n",
        "#    result_table.select(\"GROUP_IDENTIFIER_STRING\", TIME_PERIOD_COLUMN), \n",
        " #   on=[\"GROUP_IDENTIFIER_STRING\", TIME_PERIOD_COLUMN], \n",
        " #   how=\"leftanti\"\n",
        "#).drop(\"GROUP_IDENTIFIER\")\n",
        "\n",
        "print(f\"Records to predict:         {sdf.count()}\")\n",
        "sdf.show(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff3eeee1-9c6e-478a-8a1f-08cdc0eb29bf",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "md_inference"
      },
      "source": [
        "-----\n",
        "# Run Inference\n",
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4782cb9-aad2-4819-9494-810cdd77a6d7",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "language": "python",
        "name": "_inference"
      },
      "outputs": [],
      "source": [
        "if sdf.count() > 0:\n",
        "    # -----------------------------------------------------------------------\n",
        "    # Perform Batch Inference\n",
        "    # -----------------------------------------------------------------------\n",
        "    # Use the perform_inference utility to generate predictions using the registered model.\n",
        "    # The function handles partitioned model execution efficiently.\n",
        "    result = perform_inference(session, sdf, mv)\n",
        "    \n",
        "    # -----------------------------------------------------------------------\n",
        "    # Add Metadata Columns\n",
        "    # -----------------------------------------------------------------------\n",
        "    # Append model name, version, and timestamp for tracking and auditing purposes.\n",
        "    result = (\n",
        "        result\n",
        "        .with_column(\"INFERENCE_DTTM\",F.lit(current_dttm))\n",
        "        .rename(\"_PRED_\", \"PREDICTION\")\n",
        "        .join(\n",
        "            sdf.select(TIME_PERIOD_COLUMN,\"GROUP_IDENTIFIER\",\"GROUP_IDENTIFIER_STRING\",\"MODEL_TARGET\"),\n",
        "            on=[TIME_PERIOD_COLUMN,\"GROUP_IDENTIFIER_STRING\"]\n",
        "        )\n",
        "    ).select(result_table.columns)\n",
        "            \n",
        "    \n",
        "    print(\"Inference complete. Sample results:\")\n",
        "    result.show()\n",
        "\n",
        "    # Append Predictions to Results Table\n",
        "    # -----------------------------------------------------------------------\n",
        "    # Append the new predictions to the results table.\n",
        "    # Using 'append' mode ensures we don't overwrite existing predictions.\n",
        "    result.write.save_as_table(inf_table_nm, mode='append')\n",
        "    \n",
        "    print(f\"Predictions saved to: {inf_table_nm}\")\n",
        "    print(f\"Inference job completed at: {datetime.now()}\")\n",
        "\n",
        "else:\n",
        "    print(\"No new records found, inference not performed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ffe7345-1279-4fa2-8f78-5bf616b6a407",
      "metadata": {
        "codeCollapsed": false,
        "language": "python",
        "name": "cell1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "forecast",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "lastEditStatus": {
      "authorEmail": "allie.feras@snowflake.com",
      "authorId": "8790037420708",
      "authorName": "AFERAS",
      "lastEditTime": 1768514087291,
      "notebookId": "vlgs6tikqg3n4qbihfh6",
      "sessionId": "b231a1d5-9656-4011-b33a-9164517d523a"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
