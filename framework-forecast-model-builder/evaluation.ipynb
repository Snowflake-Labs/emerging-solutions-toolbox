{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ce110000-1111-2222-3333-ffffff000000",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "md_title"
      },
      "source": [
        "# Evaluation Notebook\n",
        "Use the model trained in the modeling notebook to make and evaluate predictions on a test dataset.\n",
        "\n",
        "#### NOTE: The user must have split data into train/test datasets in the modeling notebook before running this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce110000-1111-2222-3333-ffffff000001",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "md_instructions"
      },
      "source": [
        "❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ \n",
        "## Instructions\n",
        "\n",
        "1. Go to the ____set_global_variables___ cell in the __SETUP__ section below. \n",
        "    - Adjust the values of the user constants\n",
        "2. Click ___Run all___ in the upper right corner of the notebook to run the entire notebook. \n",
        "    - The notebook will perform inference and evaluation. \n",
        "    - PROMOTE_MODEL is set to false. If evaluation is satisfactory, change the value at the end of the notebook and run the last 2 cells. If model is promoted, predictions on test data will be stored in a Snowflake table and a model monitor will be create to track future inference values.\n",
        "    \n",
        "❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce110000-1111-2222-3333-ffffff000002",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "language": "python",
        "name": "_imports"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import math\n",
        "import json\n",
        "from datetime import datetime\n",
        "from snowflake.ml.registry import registry\n",
        "from snowflake.ml.dataset import Dataset\n",
        "from snowflake.snowpark import functions as F\n",
        "from snowflake.snowpark import types as T\n",
        "from snowflake.snowpark.window import Window\n",
        "from snowflake.snowpark import DataFrame as SnowparkDataFrame\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from forecast_model_builder.utils import connect, perform_inference"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce110000-1111-2222-3333-ffffff000004",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "md_USER_SETUP"
      },
      "source": [
        "-----\n",
        "# SETUP\n",
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ce110000-1111-2222-3333-ffffff000005",
      "metadata": {
        "language": "python",
        "name": "_set_global_variables"
      },
      "outputs": [],
      "source": [
        "# Name of project\n",
        "PROJECT_SCHEMA = \"TEST_PROJECT\"\n",
        "\n",
        "# Set warehouse\n",
        "SESSION_WH = \"FORECAST_MODEL_BUILDER_WH\"\n",
        "\n",
        "# Table name to store the PREDICTION results.\n",
        "# NOTE: If the table name is not fully qualified with DB.SCHEMA, the session's default database and schema will be used.\n",
        "# NOTE: Model version will be appended to the table name to save predictions from a particular run.\n",
        "INFERENCE_RESULT_TBL_NM = \"FORECAST_RESULTS\"\n",
        "\n",
        "# Input data for inference\n",
        "INFERENCE_DB = \"FORECAST_MODEL_BUILDER\"\n",
        "INFERENCE_SCHEMA = \"BASE\"\n",
        "INFERENCE_FV = \"FORECAST_FEATURES\"\n",
        "\n",
        "# Name of the model to use for inference, as well as the Database and Schema of the model registry.\n",
        "# NOTE: The default model version from the registry will be used.\n",
        "MODEL_DB = \"FORECAST_MODEL_BUILDER\"\n",
        "MODEL_SCHEMA = \"MODELING\"\n",
        "MODEL_NAME = \"TEST_MODEL_1\"\n",
        "\n",
        "# If using direct multistep forecasting, set LEAD to the lead model you wish to evaluate.\n",
        "# Otherwise, set to 0\n",
        "LEAD = 0\n",
        "\n",
        "# Scaling up the warehouse may speed up execution time, especially if there are many partitions.\n",
        "# NOTE: If set to None, then the session warehouse will be used.\n",
        "INFERENCE_WH = \"STANDARD_XL\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce110000-1111-2222-3333-ffffff000003",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "language": "python",
        "name": "_establish_session"
      },
      "outputs": [],
      "source": [
        "# Establish session\n",
        "session = connect(connection_name=\"default\")\n",
        "session.use_database(MODEL_DB)\n",
        "session_db = MODEL_DB\n",
        "session.use_schema(PROJECT_SCHEMA)\n",
        "session_schema = PROJECT_SCHEMA\n",
        "print(f\"Session db.schema: {session_db}.{session_schema}\")\n",
        "print(f\"Session warehouse: {SESSION_WH}\")\n",
        "\n",
        "# Query tag\n",
        "query_tag = '{\"origin\":\"sf_sit\", \"name\":\"sit_forecasting\", \"version\":{\"major\":1, \"minor\":0}, \"attributes\":{\"component\":\"inference\"}}'\n",
        "session.query_tag = query_tag\n",
        "\n",
        "# Get the current datetime  (This will be saved in the model storage table)\n",
        "run_dttm = datetime.now()\n",
        "print(f\"Current Datetime: {run_dttm}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce110000-1111-2222-3333-ffffff000006",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "md_objects"
      },
      "source": [
        "-----\n",
        "# Establish objects needed for this run\n",
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce110000-1111-2222-3333-ffffff000007",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "language": "python",
        "name": "_set_other_objects"
      },
      "outputs": [],
      "source": [
        "# Derived Objects\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "# Notebook Warehouse\n",
        "# -----------------------------------------------------------------------\n",
        "session.use_warehouse(SESSION_WH)\n",
        "print(f\"Session warehouse:          {SESSION_WH}\")\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "# Check Inference Warehouse\n",
        "# -----------------------------------------------------------------------\n",
        "# Check that the user specified an available warehouse as INFERENCE_WH. If not, use the session warehouse.\n",
        "available_warehouses = [\n",
        "    row[\"NAME\"]\n",
        "    for row in session.sql(\"SHOW WAREHOUSES\")\n",
        "    .select(F.col('\"name\"').alias(\"NAME\"))\n",
        "    .collect()\n",
        "]\n",
        "\n",
        "if INFERENCE_WH in available_warehouses:\n",
        "    print(f\"Inference warehouse:        {INFERENCE_WH} \\n\")\n",
        "else:\n",
        "    print(\n",
        "        f\"WARNING: User does not have access to INFERENCE_WH = '{INFERENCE_WH}'. Inference will use '{SESSION_WH}' instead. \\n\"\n",
        "    )\n",
        "    INFERENCE_WH = SESSION_WH\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "# Fully qualified MODEL NAME\n",
        "# -----------------------------------------------------------------------\n",
        "qualified_model_name = f\"{MODEL_DB}.{MODEL_SCHEMA}.{MODEL_NAME}\"\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "# Get the model and the version name of the default version\n",
        "# -----------------------------------------------------------------------\n",
        "# Establish registry object\n",
        "reg = registry.Registry(\n",
        "    session=session, database_name=MODEL_DB, schema_name=MODEL_SCHEMA\n",
        ")\n",
        "\n",
        "# Get the model from the registry\n",
        "mv = reg.get_model(qualified_model_name).last()\n",
        "\n",
        "# Get the default version name\n",
        "model_version_nm = mv.version_name\n",
        "\n",
        "print(f\"Model Version:              {model_version_nm}\")\n",
        "\n",
        "# --------------------------------\n",
        "# User Constants from Model Setup\n",
        "# --------------------------------\n",
        "stored_constants = mv.show_metrics()[\"user_settings\"]\n",
        "\n",
        "TIME_PERIOD_COLUMN = stored_constants[\"TIME_PERIOD_COLUMN\"]\n",
        "TARGET_COLUMN = stored_constants[\"TARGET_COLUMN\"]\n",
        "PARTITION_COLUMNS = stored_constants[\"PARTITION_COLUMNS\"]\n",
        "ALL_EXOG_COLS_HAVE_FUTURE_VALS = stored_constants[\"ALL_EXOG_COLS_HAVE_FUTURE_VALS\"]\n",
        "USE_CONTEXT = stored_constants[\"USE_CONTEXT\"]\n",
        "\n",
        "if not USE_CONTEXT:\n",
        "    MODEL_BINARY_STORAGE_TBL_NM = stored_constants[\"MODEL_BINARY_STORAGE_TBL_NM\"]\n",
        "\n",
        "if (not ALL_EXOG_COLS_HAVE_FUTURE_VALS) & (LEAD==0):\n",
        "    raise ValueError(\n",
        "        \"\"\"If using direct multistep modeling approach, LEAD must be set to a number \n",
        "        greater than 0 to filter results to a particular lead model\"\"\"\n",
        "    )\n",
        "if (ALL_EXOG_COLS_HAVE_FUTURE_VALS) & (LEAD>0):\n",
        "    raise ValueError(\n",
        "        \"\"\"If using global modeling approach, LEAD must be set to a 0\"\"\"\n",
        "    )\n",
        "# --------------------------------\n",
        "# Get datasets\n",
        "# --------------------------------\n",
        "\n",
        "def load_df_from_ds(fully_qualified_name, version):\n",
        "    ds_db, ds_schema, ds_name = fully_qualified_name.split('.')\n",
        "\n",
        "    return Dataset(\n",
        "        session=session,\n",
        "        database=ds_db,\n",
        "        schema=ds_schema,\n",
        "        name=ds_name,\n",
        "        selected_version=version\n",
        "    ).read.to_snowpark_dataframe()\n",
        "\n",
        "train_df = load_df_from_ds(\n",
        "    fully_qualified_name=mv.show_metrics()['train_dataset']['name'],\n",
        "    version=mv.show_metrics()['train_dataset']['version']\n",
        ").drop(\"GROUP_IDENTIFIER\")\n",
        "\n",
        "test_df = load_df_from_ds(\n",
        "    fully_qualified_name=mv.show_metrics()['test_dataset']['name'],\n",
        "    version=mv.show_metrics()['test_dataset']['version']\n",
        ").drop(\"GROUP_IDENTIFIER\")\n",
        "\n",
        "# Filter to a particular lead model if performing direct multi step forecasting\n",
        "if LEAD > 0:\n",
        "    train_df = train_df.filter(\n",
        "            F.col(\"GROUP_IDENTIFIER_STRING\").endswith(f\"LEAD_{LEAD}\")\n",
        "        )\n",
        "    test_df = test_df.filter(\n",
        "            F.col(\"GROUP_IDENTIFIER_STRING\").endswith(f\"LEAD_{LEAD}\")\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce110000-1111-2222-3333-ffffff000012",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "md_inference"
      },
      "source": [
        "-----\n",
        "# Inference\n",
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ce110000-1111-2222-3333-ffffff000013",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "language": "python",
        "name": "_perform_inference"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------------------\n",
        "# INFERENCE\n",
        "# ------------------------------------------------------------------------\n",
        "\n",
        "print(\"Predictions\")\n",
        "session.use_warehouse(INFERENCE_WH)\n",
        "\n",
        "train_result = perform_inference(session, train_df, mv).with_column(\"DATASET\",F.lit(\"TRAIN\")).cache_result()\n",
        "test_result = perform_inference(session, test_df, mv).with_column(\"DATASET\",F.lit(\"TEST\")).cache_result()\n",
        "test_result.show(2)\n",
        "\n",
        "\n",
        "inference_result = train_result.union_all_by_name(test_result)\n",
        "session.use_warehouse(SESSION_WH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce110000-1111-2222-3333-ffffff000008",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "language": "python",
        "name": "_pred_v_actual"
      },
      "outputs": [],
      "source": [
        "# Get predicted vs. actual dataframes for train and test\n",
        "\n",
        "sdf = train_df.union_all_by_name(test_df).select(\"GROUP_IDENTIFIER_STRING\",TIME_PERIOD_COLUMN,TARGET_COLUMN)\n",
        "\n",
        "pred_v_actuals = (\n",
        "    inference_result\n",
        "    .join(sdf, on=[\"GROUP_IDENTIFIER_STRING\", TIME_PERIOD_COLUMN])\n",
        "    .select(\n",
        "        \"GROUP_IDENTIFIER_STRING\", \n",
        "        TIME_PERIOD_COLUMN, \n",
        "        TARGET_COLUMN,\n",
        "        F.col(\"_PRED_\").alias(\"PREDICTED\"),\n",
        "        \"DATASET\"\n",
        "    )\n",
        ")\n",
        "\n",
        "inference_partition_count = pred_v_actuals.select(\"GROUP_IDENTIFIER_STRING\").distinct().count()\n",
        "\n",
        "training_pred_v_actuals = pred_v_actuals.filter(F.col(\"DATASET\")==\"TRAIN\")\n",
        "\n",
        "test_pred_v_actuals = pred_v_actuals.filter(F.col(\"DATASET\")==\"TEST\")\n",
        "print(f\"Dataset has {inference_partition_count} partitions\")\n",
        "pred_v_actuals.show(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "ce110000-1111-2222-3333-ffffff000009",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "language": "python",
        "name": "_partition_weights"
      },
      "outputs": [],
      "source": [
        "# Calculate weights of each partition for weighted metrics\n",
        "\n",
        "total_window = Window.partition_by()\n",
        "\n",
        "partition_weights = (\n",
        "    pred_v_actuals\n",
        "    .group_by(\"GROUP_IDENTIFIER_STRING\")\n",
        "    .agg(F.sum(TARGET_COLUMN).alias(f'PARTITION_{TARGET_COLUMN}_SUM'), F.min(TIME_PERIOD_COLUMN), F.max(TIME_PERIOD_COLUMN))\n",
        "    .with_column(f\"TOTAL_{TARGET_COLUMN}\", F.sum(f'PARTITION_{TARGET_COLUMN}_SUM').over(total_window))\n",
        "    .with_column(\"PARTITION_WEIGHT\", F.col(f'PARTITION_{TARGET_COLUMN}_SUM')/F.col(f\"TOTAL_{TARGET_COLUMN}\"))\n",
        ")\n",
        "\n",
        "partition_weights.sort(F.col(\"PARTITION_WEIGHT\").desc()).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6211445-d2e9-432b-9608-c642609efe72",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "md_overall_performance"
      },
      "source": [
        "# Overall Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce110000-1111-2222-3333-ffffff000010",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "language": "python",
        "name": "_produce_metrics"
      },
      "outputs": [],
      "source": [
        "def produce_metrics(sdf: SnowparkDataFrame) -> SnowparkDataFrame:\n",
        "    # Row-level metrics\n",
        "    row_actual_v_fcst = (\n",
        "        sdf\n",
        "        .with_column(\"PRED_ERROR\", F.col(TARGET_COLUMN) - F.col(\"PREDICTED\"))\n",
        "        .with_column(\n",
        "            \"ABS_ERROR\", F.abs(F.col(TARGET_COLUMN) - F.col(\"PREDICTED\"))\n",
        "        )\n",
        "        .with_column(\n",
        "            \"APE\",\n",
        "            F.when(F.col(TARGET_COLUMN) == 0, F.lit(None)).otherwise(\n",
        "                F.abs(F.col(\"ABS_ERROR\") / F.col(TARGET_COLUMN))\n",
        "            ),\n",
        "        )\n",
        "        .with_column(\"SQ_ERROR\", F.pow(F.col(TARGET_COLUMN) - F.col(\"PREDICTED\"), 2))\n",
        "    )\n",
        "    \n",
        "    # Metrics per partition\n",
        "    partition_metrics = row_actual_v_fcst.group_by(\"GROUP_IDENTIFIER_STRING\").agg(\n",
        "        F.avg(\"APE\").alias(\"MAPE\"),\n",
        "        F.avg(\"ABS_ERROR\").alias(\"MAE\"),\n",
        "        F.sqrt(F.avg(\"SQ_ERROR\")).alias(\"RMSE\"),\n",
        "        F.count(\"*\").alias(\"TOTAL_PRED_COUNT\"),\n",
        "    )\n",
        "    \n",
        "    # Overall modeling process across all partitions\n",
        "    overall_avg_metrics = partition_metrics.agg(\n",
        "        F.avg(\"MAPE\").alias(\"OVERALL_MAPE\"),\n",
        "        F.avg(\"MAE\").alias(\"OVERALL_MAE\"),\n",
        "        F.avg(\"RMSE\").alias(\"OVERALL_RMSE\"),\n",
        "    ).with_column(\"AGGREGATION\", F.lit(\"AVG\"))\n",
        "    \n",
        "    overall_weighted_avg_metrics = (\n",
        "        partition_metrics\n",
        "            .join(partition_weights.select(\"GROUP_IDENTIFIER_STRING\", \"PARTITION_WEIGHT\"), on=[\"GROUP_IDENTIFIER_STRING\"])\n",
        "            .agg(\n",
        "                F.sum(F.col(\"PARTITION_WEIGHT\")*F.col(\"MAPE\")).alias(\"OVERALL_MAPE\"),\n",
        "                F.sum(F.col(\"PARTITION_WEIGHT\")*F.col(\"MAE\")).alias(\"OVERALL_MAE\"),\n",
        "                F.sum(F.col(\"PARTITION_WEIGHT\")*F.col(\"RMSE\")).alias(\"OVERALL_RMSE\"),\n",
        "                 )\n",
        "            .with_column(\"AGGREGATION\", F.lit(\"WEIGHTED_AVG\"))\n",
        "    )\n",
        "    \n",
        "    overall_median_metrics = partition_metrics.agg(\n",
        "        F.median(\"MAPE\").alias(\"OVERALL_MAPE\"),\n",
        "        F.median(\"MAE\").alias(\"OVERALL_MAE\"),\n",
        "        F.median(\"RMSE\").alias(\"OVERALL_RMSE\"),\n",
        "    ).with_column(\"AGGREGATION\", F.lit(\"MEDIAN\"))\n",
        "    \n",
        "    overall_metrics = (\n",
        "        overall_avg_metrics\n",
        "            .union(overall_median_metrics)\n",
        "            .union(overall_weighted_avg_metrics)\n",
        "            .select(\"AGGREGATION\", \"OVERALL_MAPE\", \"OVERALL_MAE\", \"OVERALL_RMSE\")\n",
        "            .sort(\"AGGREGATION\")\n",
        "    )\n",
        "    \n",
        "    # Show the metrics\n",
        "    if inference_partition_count == 1:\n",
        "        print(\n",
        "            \"There is only 1 partition, so these values are the metrics for that single model:\"\n",
        "        )\n",
        "        display(\n",
        "            overall_median_metrics.select(\"OVERALL_MAPE\", \"OVERALL_MAE\", \"OVERALL_RMSE\")\n",
        "        )\n",
        "    else:\n",
        "        print(\"Avg and Median of each metric over all the partitions:\")\n",
        "        display(overall_metrics)\n",
        "\n",
        "    return row_actual_v_fcst, partition_metrics\n",
        "\n",
        "print(\"TRAINING SET\")\n",
        "train_metric_sdf, train_partition_metrics = produce_metrics(training_pred_v_actuals)\n",
        "print(\"VALIDATION SET\")\n",
        "test_metric_sdf, test_partition_metrics = produce_metrics(test_pred_v_actuals)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "464115e1-dacb-4fbd-8638-6595bc802457",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "md_partition_performance"
      },
      "source": [
        "# Partition Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d63dd9d6-9a83-440e-a41c-cf58961ce3c7",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "language": "python",
        "name": "_metric_distribution"
      },
      "outputs": [],
      "source": [
        "if (len(PARTITION_COLUMNS) > 0) & (inference_partition_count > 1):\n",
        "    distribution_df = test_partition_metrics.to_pandas()\n",
        "    \n",
        "    table_to_show_sdf = (\n",
        "        test_partition_metrics\n",
        "        .join(partition_weights.select(\"GROUP_IDENTIFIER_STRING\", \"PARTITION_WEIGHT\"), on=[\"GROUP_IDENTIFIER_STRING\"])\n",
        "        .with_column(\"WGHT_PCT\", F.col(\"PARTITION_WEIGHT\")*100)\n",
        "        .select(\"GROUP_IDENTIFIER_STRING\", \"MAPE\", \"MAE\", \"RMSE\", \"WGHT_PCT\")\n",
        "    )\n",
        "    table_df = table_to_show_sdf.to_pandas()\n",
        "    \n",
        "    metrics = [\"MAPE\", \"MAE\", \"RMSE\"]\n",
        "    \n",
        "    fig = go.Figure()\n",
        "    \n",
        "    for i, metric in enumerate(metrics):\n",
        "        visible = (i == 0)\n",
        "        fig.add_trace(go.Box(\n",
        "            x=distribution_df[metric],\n",
        "            name=metric,\n",
        "            boxpoints=\"all\",\n",
        "            jitter=0.3,\n",
        "            pointpos=-1.8,\n",
        "            hovertext=distribution_df[\"GROUP_IDENTIFIER_STRING\"],\n",
        "            hoverinfo=\"text+x\",\n",
        "            visible=visible\n",
        "        ))\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title=\"MAPE Distribution\",\n",
        "        template=\"plotly_white\",\n",
        "        updatemenus=[\n",
        "            dict(\n",
        "                active=0,\n",
        "                buttons=[\n",
        "                    dict(\n",
        "                        label=metric,\n",
        "                        method=\"update\",\n",
        "                        args=[\n",
        "                            {\"visible\": [m == metric for m in metrics]},\n",
        "                            {\"title\": f\"{metric} Distribution\",\n",
        "                             \"xaxis\": {\"title\": metric, \"range\": [distribution_df[metric].min(), distribution_df[metric].max()]}}\n",
        "                        ]\n",
        "                    ) for metric in metrics\n",
        "                ],\n",
        "                direction=\"down\",\n",
        "                showactive=True,\n",
        "                x=0.0,\n",
        "                xanchor=\"left\",\n",
        "                y=1.15,\n",
        "                yanchor=\"top\"\n",
        "            )\n",
        "        ],\n",
        "        xaxis=dict(\n",
        "            rangeslider=dict(visible=True),\n",
        "            title=\"MAPE\"\n",
        "        ),\n",
        "        annotations=[\n",
        "            dict(text=\"Metric:\", x=0, xref=\"paper\", y=1.12, yref=\"paper\", showarrow=False, xanchor=\"right\")\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    fig.show()\n",
        "\n",
        "    print(\"## BEST Performing Partitions (sorted by MAPE)\")\n",
        "    display(table_df.sort_values(\"MAPE\", key=abs).head(20))\n",
        "    \n",
        "    print(\"## WORST Performing Partitions (sorted by MAPE desc)\")\n",
        "    display(table_df.sort_values(\"MAPE\", key=abs, ascending=False).head(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "345df61d-96ed-4272-a298-e20d61acf0de",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "language": "python",
        "name": "_partition_plots"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# Visualize individual partition actual vs pred on a time series line chart\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "pred_v_actuals_pdf = pred_v_actuals.to_pandas()\n",
        "pred_v_actuals_pdf[TIME_PERIOD_COLUMN] = pd.to_datetime(pred_v_actuals_pdf[TIME_PERIOD_COLUMN])\n",
        "partition_list = sorted(pred_v_actuals_pdf[\"GROUP_IDENTIFIER_STRING\"].unique().tolist())\n",
        "\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=1,\n",
        "    subplot_titles=(\"Line Plot: Actual & Predicted\", \"Scatter Plot: Actual vs. Predicted\"),\n",
        "    vertical_spacing=0.15\n",
        ")\n",
        "\n",
        "for i, partition in enumerate(partition_list):\n",
        "    pdf = pred_v_actuals_pdf[pred_v_actuals_pdf[\"GROUP_IDENTIFIER_STRING\"] == partition].sort_values(TIME_PERIOD_COLUMN)\n",
        "    visible = (i == 0)\n",
        "    \n",
        "    split_date = pdf[pdf[\"DATASET\"] == \"TRAIN\"][TIME_PERIOD_COLUMN].max()\n",
        "    \n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=pdf[TIME_PERIOD_COLUMN], y=pdf[TARGET_COLUMN],\n",
        "        mode=\"lines\", name=\"Actual\", line=dict(color=\"blue\"),\n",
        "        visible=visible, legendgroup=partition, showlegend=True\n",
        "    ), row=1, col=1)\n",
        "    \n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=pdf[TIME_PERIOD_COLUMN], y=pdf[\"PREDICTED\"],\n",
        "        mode=\"lines\", name=\"Predicted\", line=dict(color=\"red\"),\n",
        "        visible=visible, legendgroup=partition, showlegend=True\n",
        "    ), row=1, col=1)\n",
        "    \n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=[split_date, split_date], y=[pdf[TARGET_COLUMN].min(), pdf[TARGET_COLUMN].max()],\n",
        "        mode=\"lines\", name=\"Forecast Start\", line=dict(color=\"green\", dash=\"dash\"),\n",
        "        visible=visible, legendgroup=partition, showlegend=True\n",
        "    ), row=1, col=1)\n",
        "    \n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=pdf[TARGET_COLUMN], y=pdf[\"PREDICTED\"],\n",
        "        mode=\"markers\", name=\"Actual vs Pred\", opacity=0.6,\n",
        "        visible=visible, legendgroup=partition, showlegend=False\n",
        "    ), row=2, col=1)\n",
        "    \n",
        "    min_val, max_val = pdf[TARGET_COLUMN].min(), pdf[TARGET_COLUMN].max()\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=[min_val, max_val], y=[min_val, max_val],\n",
        "        mode=\"lines\", name=\"y=x\", line=dict(color=\"black\", dash=\"dash\"),\n",
        "        visible=visible, legendgroup=partition, showlegend=True\n",
        "    ), row=2, col=1)\n",
        "\n",
        "traces_per_partition = 5\n",
        "\n",
        "buttons = []\n",
        "for i, partition in enumerate(partition_list):\n",
        "    visibility = [False] * (len(partition_list) * traces_per_partition)\n",
        "    for j in range(traces_per_partition):\n",
        "        visibility[i * traces_per_partition + j] = True\n",
        "    buttons.append(dict(\n",
        "        label=partition,\n",
        "        method=\"update\",\n",
        "        args=[{\"visible\": visibility}, {\"title\": f\"Partition: {partition}\"}]\n",
        "    ))\n",
        "\n",
        "fig.update_layout(\n",
        "    height=800,\n",
        "    title=f\"Partition: {partition_list[0]}\",\n",
        "    updatemenus=[dict(\n",
        "        active=0,\n",
        "        buttons=buttons,\n",
        "        direction=\"down\",\n",
        "        showactive=True,\n",
        "        x=0.0,\n",
        "        xanchor=\"left\",\n",
        "        y=1.08,\n",
        "        yanchor=\"top\"\n",
        "    )],\n",
        "    annotations=[\n",
        "        dict(text=\"Partition:\", x=0, xref=\"paper\", y=1.06, yref=\"paper\", showarrow=False, xanchor=\"right\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "fig.update_xaxes(title_text=TIME_PERIOD_COLUMN, row=1, col=1)\n",
        "fig.update_xaxes(title_text=TARGET_COLUMN, row=2, col=1)\n",
        "fig.update_yaxes(title_text=\"Value\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"PREDICTED\", row=2, col=1)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f597411c-0adb-4298-a4f9-4fb4c78c1db0",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "md_feature_importance"
      },
      "source": [
        "# Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38ecdf96-13a7-4646-8a61-616cd64f9f19",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "language": "python",
        "name": "_get_feature_importance"
      },
      "outputs": [],
      "source": [
        "# Load model feature important data depending on use of model context or storage table\n",
        "\n",
        "if USE_CONTEXT:\n",
        "    model_obj = mv.load(force=True).context.model_refs\n",
        "    model_data = [(\n",
        "        part, \n",
        "        dict(feature_importance=dict(\n",
        "            zip(ref.model.feature_names_in_, [float(val) for val in ref.model.feature_importances_])\n",
        "        ))\n",
        "    ) for part,ref in model_obj.items()]\n",
        "\n",
        "    model_df = pd.DataFrame(model_data,columns=[\"GROUP_IDENTIFIER_STRING\",\"METADATA\"])\n",
        "    model_df[\"MODEL_NAME\"] = MODEL_NAME\n",
        "    print(\n",
        "        f\"Feature Importances are from model version {model_version_nm} model context.\"\n",
        "    )\n",
        "else:\n",
        "    models_sdf = (\n",
        "        session.table(f\"{MODEL_BINARY_STORAGE_TBL_NM}\")\n",
        "        .filter(F.col(\"MODEL_NAME\") == MODEL_NAME)\n",
        "        .filter(\n",
        "            F.col(\"MODEL_VERSION\")\n",
        "            == reg.get_model(qualified_model_name).default.version_name\n",
        "        )\n",
        "    )\n",
        "    model_df = models_sdf.select(\n",
        "        \"MODEL_NAME\", \"GROUP_IDENTIFIER_STRING\", \"METADATA\"\n",
        "    ).to_pandas()\n",
        "    print(\n",
        "        f\"Feature Importances are for model version {reg.get_model(qualified_model_name).default.version_name} in table {MODEL_BINARY_STORAGE_TBL_NM}.\"\n",
        "    )\n",
        "\n",
        "# Filter models to given lead if using direct multistep modeling\n",
        "if LEAD > 0:\n",
        "    model_df = model_df[\n",
        "        model_df[\"GROUP_IDENTIFIER_STRING\"].str.endswith(f\"LEAD_{LEAD}\")\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48a97be1-2646-4304-8a5b-55b77c13ab9d",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "language": "python",
        "name": "_plot_feature_importance"
      },
      "outputs": [],
      "source": [
        "def preprocess_model_data(df):\n",
        "    \"\"\"Preprocess model data by extracting feature importance from the METADATA column.\"\"\"\n",
        "    df[\"FEATURE_IMPORTANCE\"] = df[\"METADATA\"].apply(\n",
        "        lambda x: (\n",
        "            json.loads(x).get(\"feature_importance\", {})\n",
        "            if isinstance(x, str)\n",
        "            else x.get(\"feature_importance\", {})\n",
        "        )\n",
        "    )\n",
        "\n",
        "    feature_rows = []\n",
        "    for _, row in df.iterrows():\n",
        "        for feature, importance in row[\"FEATURE_IMPORTANCE\"].items():\n",
        "            feature_rows.append(\n",
        "                {\n",
        "                    \"MODEL_NAME\": row[\"MODEL_NAME\"],\n",
        "                    \"GROUP_IDENTIFIER_STRING\": row[\"GROUP_IDENTIFIER_STRING\"],\n",
        "                    \"FEATURE\": feature,\n",
        "                    \"IMPORTANCE\": importance,\n",
        "                }\n",
        "            )\n",
        "\n",
        "    feature_df = pd.DataFrame(feature_rows)\n",
        "    return df, feature_df\n",
        "\n",
        "\n",
        "def calculate_average_rank(feature_df):\n",
        "    \"\"\"Calculate the average rank and importance of features across different group partitions.\"\"\"\n",
        "    feature_df = feature_df.copy()\n",
        "    feature_df.loc[:, \"RANK\"] = feature_df.groupby(\"GROUP_IDENTIFIER_STRING\")[\n",
        "        \"IMPORTANCE\"\n",
        "    ].rank(ascending=False)\n",
        "\n",
        "    avg_rank_df = (\n",
        "        feature_df.groupby(\"FEATURE\")\n",
        "        .agg({\"RANK\": \"mean\", \"IMPORTANCE\": \"mean\"})\n",
        "        .reset_index()\n",
        "    )\n",
        "\n",
        "    avg_rank_df.rename(\n",
        "        columns={\"RANK\": \"AVERAGE_RANK\", \"IMPORTANCE\": \"AVERAGE_IMPORTANCE\"},\n",
        "        inplace=True,\n",
        "    )\n",
        "    avg_rank_df = avg_rank_df.sort_values(\"AVERAGE_RANK\", ascending=True)\n",
        "    return feature_df, avg_rank_df\n",
        "\n",
        "\n",
        "model_df, feature_df = preprocess_model_data(model_df)\n",
        "partition_models = sorted(model_df[\"GROUP_IDENTIFIER_STRING\"].unique().tolist())\n",
        "\n",
        "_, avg_rank_df_all = calculate_average_rank(feature_df)\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "top_n_values = [10, 20, 30, 40, 50]\n",
        "default_top_n = 20\n",
        "\n",
        "agg_df = avg_rank_df_all.sort_values(\"AVERAGE_RANK\").head(default_top_n)\n",
        "fig.add_trace(go.Bar(\n",
        "    y=agg_df[\"FEATURE\"],\n",
        "    x=agg_df[\"AVERAGE_RANK\"],\n",
        "    orientation=\"h\",\n",
        "    name=\"Aggregated\",\n",
        "    visible=True\n",
        "))\n",
        "\n",
        "for partition in partition_models:\n",
        "    part_df = feature_df[feature_df[\"GROUP_IDENTIFIER_STRING\"] == partition]\n",
        "    part_df = part_df.sort_values(\"IMPORTANCE\", ascending=False).head(default_top_n)\n",
        "    fig.add_trace(go.Bar(\n",
        "        y=part_df[\"FEATURE\"],\n",
        "        x=part_df[\"IMPORTANCE\"],\n",
        "        orientation=\"h\",\n",
        "        name=partition,\n",
        "        visible=False\n",
        "    ))\n",
        "\n",
        "partition_buttons = [\n",
        "    dict(\n",
        "        label=\"Aggregated (All)\",\n",
        "        method=\"update\",\n",
        "        args=[\n",
        "            {\"visible\": [True] + [False] * len(partition_models)},\n",
        "            {\"title\": \"Feature Importance (Aggregated by Average Rank)\", \"xaxis.title\": \"Average Rank\"}\n",
        "        ]\n",
        "    )\n",
        "]\n",
        "\n",
        "for i, partition in enumerate(partition_models):\n",
        "    visibility = [False] * (1 + len(partition_models))\n",
        "    visibility[i + 1] = True\n",
        "    partition_buttons.append(dict(\n",
        "        label=partition[:30] + \"...\" if len(partition) > 30 else partition,\n",
        "        method=\"update\",\n",
        "        args=[\n",
        "            {\"visible\": visibility},\n",
        "            {\"title\": f\"Feature Importance: {partition}\", \"xaxis.title\": \"Importance\"}\n",
        "        ]\n",
        "    ))\n",
        "\n",
        "top_n_steps = []\n",
        "for top_n in top_n_values:\n",
        "    agg_df_n = avg_rank_df_all.sort_values(\"AVERAGE_RANK\").head(top_n)\n",
        "    step = dict(\n",
        "        method=\"restyle\",\n",
        "        args=[{\"y\": [agg_df_n[\"FEATURE\"].tolist()], \"x\": [agg_df_n[\"AVERAGE_RANK\"].tolist()]}, [0]],\n",
        "        label=str(top_n)\n",
        "    )\n",
        "    top_n_steps.append(step)\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Feature Importance (Aggregated by Average Rank)\",\n",
        "    xaxis_title=\"Average Rank\",\n",
        "    yaxis_title=\"Feature\",\n",
        "    yaxis=dict(categoryorder=\"total descending\"),\n",
        "    height=600,\n",
        "    margin=dict(l=200, r=50, t=100, b=50),\n",
        "    updatemenus=[\n",
        "        dict(\n",
        "            active=0,\n",
        "            buttons=partition_buttons,\n",
        "            direction=\"down\",\n",
        "            showactive=True,\n",
        "            x=0.0,\n",
        "            xanchor=\"left\",\n",
        "            y=1.15,\n",
        "            yanchor=\"top\"\n",
        "        )\n",
        "    ],\n",
        "    sliders=[dict(\n",
        "        active=1,\n",
        "        currentvalue={\"prefix\": \"Top N Features: \"},\n",
        "        pad={\"t\": 50},\n",
        "        steps=top_n_steps\n",
        "    )],\n",
        "    annotations=[\n",
        "        dict(text=\"Partition:\", x=0, xref=\"paper\", y=1.12, yref=\"paper\", showarrow=False, xanchor=\"right\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "print(\"## Underlying Data - Average Importance (Top 20)\")\n",
        "display(avg_rank_df_all.sort_values(\"AVERAGE_RANK\").head(20))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bdf424e-e4c8-483e-b0e5-0dd004010c2f",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "md_model_promotion"
      },
      "source": [
        "# Promote Model Version?\n",
        "\n",
        "If set to True, model version evaluated in this notebook will be promoted to default and a new inference table will be created from the test data. A model monitor to track future inference results will also be created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6a7f372-46c8-48bc-95c1-bc9863660158",
      "metadata": {
        "language": "python",
        "name": "_set_decision_value"
      },
      "outputs": [],
      "source": [
        "PROMOTE_MODEL_VERSION = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a24ad5f0-3e96-4550-9a45-889c0efba434",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "language": "python",
        "name": "_promote_and_monitor"
      },
      "outputs": [],
      "source": [
        "if PROMOTE_MODEL_VERSION:\n",
        "    m = reg.get_model(qualified_model_name)\n",
        "    m.default = model_version_nm\n",
        "    print(f\"Model version {model_version_nm} promoted.\")\n",
        "    session.use_schema(MODEL_SCHEMA)\n",
        "    source_name = f\"{INFERENCE_RESULT_TBL_NM}_{MODEL_NAME}_{model_version_nm}\"\n",
        "    base_name = source_name + \"_BASELINE\"\n",
        "    table_exist = session.sql(f\"SHOW TABLES LIKE '{source_name}';\").count() > 0\n",
        "    if table_exist:\n",
        "        table_data = session.table(source_name).select(TIME_PERIOD_COLUMN,\"GROUP_IDENTIFIER_STRING\")\n",
        "        data_to_save = test_pred_v_actuals.join(table_data, on = [TIME_PERIOD_COLUMN, \"GROUP_IDENTIFIER_STRING\"], how=\"leftanti\")\n",
        "        data_to_save.drop(\"DATASET\").write.save_as_table(source_name, mode=\"append\")\n",
        "    else:\n",
        "        test_pred_v_actuals.drop(\"DATASET\").write.save_as_table(source_name, mode=\"overwrite\")\n",
        "    session.sql(f\"\"\"\n",
        "        CREATE OR REPLACE MODEL MONITOR {MODEL_NAME}_{model_version_nm}_MONITOR\n",
        "        WITH\n",
        "            MODEL={MODEL_NAME}\n",
        "            VERSION={model_version_nm}\n",
        "            FUNCTION=predict\n",
        "            SOURCE={source_name}\n",
        "            TIMESTAMP_COLUMN={TIME_PERIOD_COLUMN}\n",
        "            PREDICTION_SCORE_COLUMNS=(PREDICTED)  \n",
        "            ACTUAL_SCORE_COLUMNS=(MODEL_TARGET)\n",
        "            SEGMENT_COLUMNS = (GROUP_IDENTIFIER_STRING)\n",
        "            WAREHOUSE={SESSION_WH}\n",
        "            REFRESH_INTERVAL='1 day'\n",
        "            AGGREGATION_WINDOW='1 day';\n",
        "    \"\"\").collect()\n",
        "    print(\"Model monitor created\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "forecast",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "lastEditStatus": {
      "authorEmail": "allie.feras@snowflake.com",
      "authorId": "8790037420708",
      "authorName": "AFERAS",
      "lastEditTime": 1766443100328,
      "notebookId": "p5makmw26y5bvxul3p5k",
      "sessionId": "f1f8a20a-5c66-44d5-ae69-a66f3b95bd27"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
