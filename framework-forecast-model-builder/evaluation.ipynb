{
 "metadata": {
  "kernelspec": {
   "display_name": "forecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "lastEditStatus": {
   "notebookId": "p5makmw26y5bvxul3p5k",
   "authorId": "8790037420708",
   "authorName": "AFERAS",
   "authorEmail": "allie.feras@snowflake.com",
   "sessionId": "f1f8a20a-5c66-44d5-ae69-a66f3b95bd27",
   "lastEditTime": 1766443100328
  }
 },
 "nbformat_minor": 2,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000000",
   "metadata": {
    "collapsed": false,
    "name": "md_title"
   },
   "source": [
    "# Evaluation Notebook\n",
    "Use the model trained in the modeling notebook to make and evaluate predictions on a test dataset.\n",
    "\n",
    "#### NOTE: The user must have split data into train/test datasets in the modeling notebook before running this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000001",
   "metadata": {
    "collapsed": false,
    "name": "md_instructions"
   },
   "source": "❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ \n## Instructions\n\n1. Go to the ____set_global_variables___ cell in the __SETUP__ section below. \n    - Adjust the values of the user constants\n2. Click ___Run all___ in the upper right corner of the notebook to run the entire notebook. \n    - The notebook will perform inference and evaluation. \n    - PROMOTE_MODEL is set to false. If evaluation is satisfactory, change the value at the end of the notebook and run the last 2 cells. If model is promoted, predictions on test data will be stored in a Snowflake table and a model monitor will be create to track future inference values.\n    \n❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ "
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce110000-1111-2222-3333-ffffff000002",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "_imports"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/forecast/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import math\n",
    "import json\n",
    "from datetime import datetime\n",
    "from snowflake.ml.registry import registry\n",
    "from snowflake.ml.dataset import Dataset\n",
    "from snowflake.snowpark import functions as F\n",
    "from snowflake.snowpark import types as T\n",
    "from snowflake.snowpark.window import Window\n",
    "from snowflake.snowpark import DataFrame as SnowparkDataFrame\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from forecast_model_builder.utils import connect, perform_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce110000-1111-2222-3333-ffffff000003",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "_establish_session"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session db.schema: FORECAST_MODEL_BUILDER.TEST\n",
      "Session warehouse: FORECAST_MODEL_BUILDER_WH\n",
      "Current Datetime: 2025-10-27 09:54:59.647568\n"
     ]
    }
   ],
   "source": [
    "# Establish session\n",
    "session = connect(connection_name=\"default\")\n",
    "session_db = session.connection.database\n",
    "session_schema = session.connection.schema\n",
    "session_wh = session.connection.warehouse\n",
    "print(f\"Session db.schema: {session_db}.{session_schema}\")\n",
    "print(f\"Session warehouse: {session_wh}\")\n",
    "\n",
    "# Query tag\n",
    "query_tag = '{\"origin\":\"sf_sit\", \"name\":\"sit_forecasting\", \"version\":{\"major\":1, \"minor\":0}, \"attributes\":{\"component\":\"inference\"}}'\n",
    "session.query_tag = query_tag\n",
    "\n",
    "# Get the current datetime  (This will be saved in the model storage table)\n",
    "run_dttm = datetime.now()\n",
    "print(f\"Current Datetime: {run_dttm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000004",
   "metadata": {
    "collapsed": false,
    "name": "md_USER_SETUP"
   },
   "source": [
    "-----\n",
    "# SETUP\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce110000-1111-2222-3333-ffffff000005",
   "metadata": {
    "language": "python",
    "name": "_set_global_variables"
   },
   "outputs": [],
   "source": "# Table name to store the PREDICTION results.\n# NOTE: If the table name is not fully qualified with DB.SCHEMA, the session's default database and schema will be used.\n# NOTE: Model version will be appended to the table name to save predictions from a particular run.\nINFERENCE_RESULT_TBL_NM = \"FORECAST_RESULTS\"\n\n# Input data for inference\nINFERENCE_DB = \"FORECAST_MODEL_BUILDER\"\nINFERENCE_SCHEMA = \"BASE\"\nINFERENCE_FV = \"FORECAST_FEATURES\"\n\n# Name of the model to use for inference, as well as the Database and Schema of the model registry.\n# NOTE: The default model version from the registry will be used.\nMODEL_DB = \"FORECAST_MODEL_BUILDER\"\nMODEL_SCHEMA = \"MODELING\"\nMODEL_NAME = \"TEST_MODEL_1\"\n\n# If using direct multistep forecasting, set LEAD to the lead model you wish to evaluate.\n# Otherwise, set to 0\nLEAD = 0\n\n# Scaling up the warehouse may speed up execution time, especially if there are many partitions.\n# NOTE: If set to None, then the session warehouse will be used.\nINFERENCE_WH = \"STANDARD_XL\""
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000006",
   "metadata": {
    "collapsed": false,
    "name": "md_objects"
   },
   "source": [
    "-----\n",
    "# Establish objects needed for this run\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000007",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "_set_other_objects"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session warehouse:          FORECAST_MODEL_BUILDER_WH\n",
      "WARNING: User does not have access to INFERENCE_WH = 'STANDARD_XL'. Inference will use 'FORECAST_MODEL_BUILDER_WH' instead. \n",
      "\n",
      "Model Version:              COWARDLY_BADGER_3\n"
     ]
    }
   ],
   "source": "# Derived Objects\n\n# -----------------------------------------------------------------------\n# Notebook Warehouse\n# -----------------------------------------------------------------------\nSESSION_WH = session.connection.warehouse\nprint(f\"Session warehouse:          {SESSION_WH}\")\n\n# -----------------------------------------------------------------------\n# Check Inference Warehouse\n# -----------------------------------------------------------------------\n# Check that the user specified an available warehouse as INFERENCE_WH. If not, use the session warehouse.\navailable_warehouses = [\n    row[\"NAME\"]\n    for row in session.sql(\"SHOW WAREHOUSES\")\n    .select(F.col('\"name\"').alias(\"NAME\"))\n    .collect()\n]\n\nif INFERENCE_WH in available_warehouses:\n    print(f\"Inference warehouse:        {INFERENCE_WH} \\n\")\nelse:\n    print(\n        f\"WARNING: User does not have access to INFERENCE_WH = '{INFERENCE_WH}'. Inference will use '{SESSION_WH}' instead. \\n\"\n    )\n    INFERENCE_WH = SESSION_WH\n\n# -----------------------------------------------------------------------\n# Fully qualified MODEL NAME\n# -----------------------------------------------------------------------\nqualified_model_name = f\"{MODEL_DB}.{MODEL_SCHEMA}.{MODEL_NAME}\"\n\n# -----------------------------------------------------------------------\n# Get the model and the version name of the default version\n# -----------------------------------------------------------------------\n# Establish registry object\nreg = registry.Registry(\n    session=session, database_name=MODEL_DB, schema_name=MODEL_SCHEMA\n)\n\n# Get the model from the registry\nmv = reg.get_model(qualified_model_name).last()\n\n# Get the default version name\nmodel_version_nm = mv.version_name\n\nprint(f\"Model Version:              {model_version_nm}\")\n\n# --------------------------------\n# User Constants from Model Setup\n# --------------------------------\nstored_constants = mv.show_metrics()[\"user_settings\"]\n\nTIME_PERIOD_COLUMN = stored_constants[\"TIME_PERIOD_COLUMN\"]\nTARGET_COLUMN = stored_constants[\"TARGET_COLUMN\"]\nPARTITION_COLUMNS = stored_constants[\"PARTITION_COLUMNS\"]\nALL_EXOG_COLS_HAVE_FUTURE_VALS = stored_constants[\"ALL_EXOG_COLS_HAVE_FUTURE_VALS\"]\nUSE_CONTEXT = stored_constants[\"USE_CONTEXT\"]\n\nif not USE_CONTEXT:\n    MODEL_BINARY_STORAGE_TBL_NM = stored_constants[\"MODEL_BINARY_STORAGE_TBL_NM\"]\n\nif (not ALL_EXOG_COLS_HAVE_FUTURE_VALS) & (LEAD==0):\n    raise ValueError(\n        \"\"\"If using direct multistep modeling approach, LEAD must be set to a number \n        greater than 0 to filter results to a particular lead model\"\"\"\n    )\nif (ALL_EXOG_COLS_HAVE_FUTURE_VALS) & (LEAD>0):\n    raise ValueError(\n        \"\"\"If using global modeling approach, LEAD must be set to a 0\"\"\"\n    )\n# --------------------------------\n# Get datasets\n# --------------------------------\n\ndef load_df_from_ds(fully_qualified_name, version):\n    ds_db, ds_schema, ds_name = fully_qualified_name.split('.')\n\n    return Dataset(\n        session=session,\n        database=ds_db,\n        schema=ds_schema,\n        name=ds_name,\n        selected_version=version\n    ).read.to_snowpark_dataframe()\n\ntrain_df = load_df_from_ds(\n    fully_qualified_name=mv.show_metrics()['train_dataset']['name'],\n    version=mv.show_metrics()['train_dataset']['version']\n).drop(\"GROUP_IDENTIFIER\")\n\ntest_df = load_df_from_ds(\n    fully_qualified_name=mv.show_metrics()['test_dataset']['name'],\n    version=mv.show_metrics()['test_dataset']['version']\n).drop(\"GROUP_IDENTIFIER\")\n\n# Filter to a particular lead model if performing direct multi step forecasting\nif LEAD > 0:\n    train_df = train_df.filter(\n            F.col(\"GROUP_IDENTIFIER_STRING\").endswith(f\"LEAD_{LEAD}\")\n        )\n    test_df = test_df.filter(\n            F.col(\"GROUP_IDENTIFIER_STRING\").endswith(f\"LEAD_{LEAD}\")\n        )\n"
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000012",
   "metadata": {
    "collapsed": false,
    "name": "md_inference"
   },
   "source": [
    "-----\n",
    "# Inference\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce110000-1111-2222-3333-ffffff000013",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "_perform_inference"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions\n",
      "Inference input data row count: 344750\n",
      "Number of end partition invocations to expect in the query profile: 1750\n",
      "Inference input data row count: 22750\n",
      "Number of end partition invocations to expect in the query profile: 250\n",
      "-----------------------------------------------------------------------------------\n",
      "|\"_PRED_\"           |\"GROUP_IDENTIFIER_STRING\"  |\"ORDER_TIMESTAMP\"    |\"DATASET\"  |\n",
      "-----------------------------------------------------------------------------------\n",
      "|968.4151000976562  |STORE_ID_9_PRODUCT_ID_8    |2024-12-06 00:00:00  |TEST       |\n",
      "|963.600830078125   |STORE_ID_9_PRODUCT_ID_8    |2024-12-17 00:00:00  |TEST       |\n",
      "-----------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": "# ------------------------------------------------------------------------\n# INFERENCE\n# ------------------------------------------------------------------------\n\nprint(\"Predictions\")\nsession.use_warehouse(INFERENCE_WH)\n\ntrain_result = perform_inference(session, train_df, mv).with_column(\"DATASET\",F.lit(\"TRAIN\")).cache_result()\ntest_result = perform_inference(session, test_df, mv).with_column(\"DATASET\",F.lit(\"TEST\")).cache_result()\ntest_result.show(2)\n\n\ninference_result = train_result.union_all_by_name(test_result)\nsession.use_warehouse(SESSION_WH)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000008",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "_pred_v_actual"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset has 250 partitions\n",
      "-------------------------------------------------------------------------------------------\n",
      "|\"GROUP_IDENTIFIER_STRING\"  |\"ORDER_TIMESTAMP\"    |\"TARGET\"           |\"PREDICTED\"        |\n",
      "-------------------------------------------------------------------------------------------\n",
      "|STORE_ID_9_PRODUCT_ID_8    |2023-07-30 00:00:00  |947.8779296875     |941.7086181640625  |\n",
      "|STORE_ID_9_PRODUCT_ID_8    |2023-05-26 00:00:00  |887.1766967773438  |888.5808715820312  |\n",
      "|STORE_ID_9_PRODUCT_ID_8    |2023-06-01 00:00:00  |880.4500122070312  |885.3113403320312  |\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get predicted vs. actual dataframes for train and test\n",
    "\n",
    "sdf = train_df.union_all_by_name(test_df).select(\"GROUP_IDENTIFIER_STRING\",TIME_PERIOD_COLUMN,TARGET_COLUMN)\n",
    "\n",
    "pred_v_actuals = (\n",
    "    inference_result\n",
    "    .join(sdf, on=[\"GROUP_IDENTIFIER_STRING\", TIME_PERIOD_COLUMN])\n",
    "    .select(\n",
    "        \"GROUP_IDENTIFIER_STRING\", \n",
    "        TIME_PERIOD_COLUMN, \n",
    "        TARGET_COLUMN,\n",
    "        F.col(\"_PRED_\").alias(\"PREDICTED\"),\n",
    "        \"DATASET\"\n",
    "    )\n",
    ")\n",
    "\n",
    "inference_partition_count = pred_v_actuals.select(\"GROUP_IDENTIFIER_STRING\").distinct().count()\n",
    "\n",
    "training_pred_v_actuals = pred_v_actuals.filter(F.col(\"DATASET\")==\"TRAIN\")\n",
    "\n",
    "test_pred_v_actuals = pred_v_actuals.filter(F.col(\"DATASET\")==\"TEST\")\n",
    "print(f\"Dataset has {inference_partition_count} partitions\")\n",
    "pred_v_actuals.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce110000-1111-2222-3333-ffffff000009",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "_partition_weights"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"GROUP_IDENTIFIER_STRING\"  |\"PARTITION_TARGET_SUM\"  |\"MIN(ORDER_TIMESTAMP)\"  |\"MAX(ORDER_TIMESTAMP)\"  |\"TOTAL_TARGET\"      |\"PARTITION_WEIGHT\"     |\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|STORE_ID_17_PRODUCT_ID_1   |1456821.035583496       |2021-01-01 00:00:00     |2025-01-09 00:00:00     |183082294.97571963  |0.00795719234225625    |\n",
      "|STORE_ID_24_PRODUCT_ID_6   |1438105.7832641602      |2021-01-01 00:00:00     |2025-01-09 00:00:00     |183082294.97571963  |0.007854969173588749   |\n",
      "|STORE_ID_22_PRODUCT_ID_3   |1411616.508605957       |2021-01-01 00:00:00     |2025-01-09 00:00:00     |183082294.97571963  |0.007710284103622175   |\n",
      "|STORE_ID_21_PRODUCT_ID_9   |1404011.4907226562      |2021-01-01 00:00:00     |2025-01-09 00:00:00     |183082294.97571963  |0.007668745308817853   |\n",
      "|STORE_ID_13_PRODUCT_ID_8   |1399447.1314697266      |2021-01-01 00:00:00     |2025-01-09 00:00:00     |183082294.97571963  |0.00764381466626973    |\n",
      "|STORE_ID_10_PRODUCT_ID_4   |1386199.2810058594      |2021-01-01 00:00:00     |2025-01-09 00:00:00     |183082294.97571963  |0.007571454581065291   |\n",
      "|STORE_ID_15_PRODUCT_ID_9   |1380295.8366699219      |2021-01-01 00:00:00     |2025-01-09 00:00:00     |183082294.97571963  |0.00753920982284484    |\n",
      "|STORE_ID_7_PRODUCT_ID_5    |1377805.5510253906      |2021-01-01 00:00:00     |2025-01-09 00:00:00     |183082294.97571963  |0.007525607821379534   |\n",
      "|STORE_ID_14_PRODUCT_ID_10  |1371382.2724609375      |2021-01-01 00:00:00     |2025-01-09 00:00:00     |183082294.97571963  |0.007490523715812117   |\n",
      "|STORE_ID_9_PRODUCT_ID_5    |1340434.5415039062      |2021-01-01 00:00:00     |2025-01-09 00:00:00     |183082294.97571963  |0.0073214864478385235  |\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate weights of each partition for weighted metrics\n",
    "\n",
    "total_window = Window.partition_by()\n",
    "\n",
    "partition_weights = (\n",
    "    pred_v_actuals\n",
    "    .group_by(\"GROUP_IDENTIFIER_STRING\")\n",
    "    .agg(F.sum(TARGET_COLUMN).alias(f'PARTITION_{TARGET_COLUMN}_SUM'), F.min(TIME_PERIOD_COLUMN), F.max(TIME_PERIOD_COLUMN))\n",
    "    .with_column(f\"TOTAL_{TARGET_COLUMN}\", F.sum(f'PARTITION_{TARGET_COLUMN}_SUM').over(total_window))\n",
    "    .with_column(\"PARTITION_WEIGHT\", F.col(f'PARTITION_{TARGET_COLUMN}_SUM')/F.col(f\"TOTAL_{TARGET_COLUMN}\"))\n",
    ")\n",
    "\n",
    "partition_weights.sort(F.col(\"PARTITION_WEIGHT\").desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6211445-d2e9-432b-9608-c642609efe72",
   "metadata": {
    "collapsed": false,
    "name": "md_overall_performance"
   },
   "source": [
    "# Overall Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000010",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "_produce_metrics"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-13 15:44:05.523 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 15:44:05.581 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /opt/anaconda3/envs/forecast/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-10-13 15:44:05.581 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 15:44:05.582 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 15:44:07.222 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 15:44:07.223 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 15:44:07.223 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 15:44:07.224 Please replace `use_container_width` with `width`.\n",
      "\n",
      "`use_container_width` will be removed after 2025-12-31.\n",
      "\n",
      "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
      "2025-10-13 15:44:17.374 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 15:44:17.376 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 15:44:17.376 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 15:44:17.377 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 15:44:17.377 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 15:44:17.378 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 15:44:18.478 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 15:44:18.479 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 15:44:18.480 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 15:44:18.480 Please replace `use_container_width` with `width`.\n",
      "\n",
      "`use_container_width` will be removed after 2025-12-31.\n",
      "\n",
      "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
      "2025-10-13 15:44:28.895 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 15:44:28.896 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-13 15:44:28.896 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "def produce_metrics(sdf: SnowparkDataFrame) -> SnowparkDataFrame:\n",
    "    # Row-level metrics\n",
    "    row_actual_v_fcst = (\n",
    "        sdf\n",
    "        .with_column(\"PRED_ERROR\", F.col(TARGET_COLUMN) - F.col(\"PREDICTED\"))\n",
    "        .with_column(\n",
    "            \"ABS_ERROR\", F.abs(F.col(TARGET_COLUMN) - F.col(\"PREDICTED\"))\n",
    "        )\n",
    "        .with_column(\n",
    "            \"APE\",\n",
    "            F.when(F.col(TARGET_COLUMN) == 0, F.lit(None)).otherwise(\n",
    "                F.abs(F.col(\"ABS_ERROR\") / F.col(TARGET_COLUMN))\n",
    "            ),\n",
    "        )\n",
    "        .with_column(\"SQ_ERROR\", F.pow(F.col(TARGET_COLUMN) - F.col(\"PREDICTED\"), 2))\n",
    "    )\n",
    "    \n",
    "    # Metrics per partition\n",
    "    partition_metrics = row_actual_v_fcst.group_by(\"GROUP_IDENTIFIER_STRING\").agg(\n",
    "        F.avg(\"APE\").alias(\"MAPE\"),\n",
    "        F.avg(\"ABS_ERROR\").alias(\"MAE\"),\n",
    "        F.sqrt(F.avg(\"SQ_ERROR\")).alias(\"RMSE\"),\n",
    "        F.count(\"*\").alias(\"TOTAL_PRED_COUNT\"),\n",
    "    )\n",
    "    \n",
    "    # Overall modeling process across all partitions\n",
    "    overall_avg_metrics = partition_metrics.agg(\n",
    "        F.avg(\"MAPE\").alias(\"OVERALL_MAPE\"),\n",
    "        F.avg(\"MAE\").alias(\"OVERALL_MAE\"),\n",
    "        F.avg(\"RMSE\").alias(\"OVERALL_RMSE\"),\n",
    "    ).with_column(\"AGGREGATION\", F.lit(\"AVG\"))\n",
    "    \n",
    "    overall_weighted_avg_metrics = (\n",
    "        partition_metrics\n",
    "            .join(partition_weights.select(\"GROUP_IDENTIFIER_STRING\", \"PARTITION_WEIGHT\"), on=[\"GROUP_IDENTIFIER_STRING\"])\n",
    "            .agg(\n",
    "                F.sum(F.col(\"PARTITION_WEIGHT\")*F.col(\"MAPE\")).alias(\"OVERALL_MAPE\"),\n",
    "                F.sum(F.col(\"PARTITION_WEIGHT\")*F.col(\"MAE\")).alias(\"OVERALL_MAE\"),\n",
    "                F.sum(F.col(\"PARTITION_WEIGHT\")*F.col(\"RMSE\")).alias(\"OVERALL_RMSE\"),\n",
    "                 )\n",
    "            .with_column(\"AGGREGATION\", F.lit(\"WEIGHTED_AVG\"))\n",
    "    )\n",
    "    \n",
    "    overall_median_metrics = partition_metrics.agg(\n",
    "        F.median(\"MAPE\").alias(\"OVERALL_MAPE\"),\n",
    "        F.median(\"MAE\").alias(\"OVERALL_MAE\"),\n",
    "        F.median(\"RMSE\").alias(\"OVERALL_RMSE\"),\n",
    "    ).with_column(\"AGGREGATION\", F.lit(\"MEDIAN\"))\n",
    "    \n",
    "    overall_metrics = (\n",
    "        overall_avg_metrics\n",
    "            .union(overall_median_metrics)\n",
    "            .union(overall_weighted_avg_metrics)\n",
    "            .select(\"AGGREGATION\", \"OVERALL_MAPE\", \"OVERALL_MAE\", \"OVERALL_RMSE\")\n",
    "            .sort(\"AGGREGATION\")\n",
    "    )\n",
    "    \n",
    "    # Show the metrics\n",
    "    if inference_partition_count == 1:\n",
    "        st.write(\n",
    "            \"There is only 1 partition, so these values are the metrics for that single model:\"\n",
    "        )\n",
    "        st.dataframe(\n",
    "            overall_median_metrics.select(\"OVERALL_MAPE\", \"OVERALL_MAE\", \"OVERALL_RMSE\"),\n",
    "            use_container_width=True,\n",
    "        )\n",
    "    else:\n",
    "        st.write(\"Avg and Median of each metric over all the partitions:\")\n",
    "        st.dataframe(overall_metrics, use_container_width=True)\n",
    "\n",
    "    return row_actual_v_fcst, partition_metrics\n",
    "\n",
    "st.write(\"TRAINING SET\")\n",
    "train_metric_sdf, train_partition_metrics = produce_metrics(training_pred_v_actuals)\n",
    "st.write(\"VALIDATION SET\")\n",
    "test_metric_sdf, test_partition_metrics = produce_metrics(test_pred_v_actuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464115e1-dacb-4fbd-8638-6595bc802457",
   "metadata": {
    "collapsed": false,
    "name": "md_partition_performance"
   },
   "source": [
    "# Partition Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63dd9d6-9a83-440e-a41c-cf58961ce3c7",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "_metric_distribution"
   },
   "outputs": [],
   "source": [
    "if (len(PARTITION_COLUMNS) > 0) & (inference_partition_count > 1):\n",
    "    # Metric Distribution plot with dynamic filtering\n",
    "    metric = st.selectbox(\"Metric\", [\"MAPE\", \"MAE\", \"RMSE\", \"WGHT_PCT\", \"GROUP_IDENTIFIER_STRING\"], key=\"metric_select_box_mnth\")\n",
    "    \n",
    "    distribution_df = test_partition_metrics.to_pandas()\n",
    "    \n",
    "    if metric not in [\"WGHT_PCT\", \"GROUP_IDENTIFIER_STRING\"]:\n",
    "        st.subheader(f\"{metric} Distribution\")\n",
    "        \n",
    "        # Add a slider to filter outliers\n",
    "        value_min, value_max = st.slider(\n",
    "            f\"Filter {metric} range in plot:\",\n",
    "            float(distribution_df[metric].min()),\n",
    "            float(distribution_df[metric].max()),\n",
    "            (float(distribution_df[metric].min()), float(distribution_df[metric].max())),\n",
    "        )\n",
    "    \n",
    "        # Filter the DataFrame based on the slider values\n",
    "        filtered_df = distribution_df[\n",
    "            (distribution_df[metric] >= value_min) & (distribution_df[metric] <= value_max)\n",
    "        ]\n",
    "    \n",
    "        fig = px.box(\n",
    "            filtered_df,\n",
    "            x=metric,  # Horizontal orientation\n",
    "            points=\"all\",  # Show individual data points as dots\n",
    "            title=f\"{metric} Distribution ({value_min:.2f} - {value_max:.2f})\",\n",
    "            labels={metric: metric, \"GROUP_IDENTIFIER_STRING\": \"Partition\"},\n",
    "            hover_data=[\"GROUP_IDENTIFIER_STRING\"],  # Add this for hover info\n",
    "        )\n",
    "\n",
    "        fig.update_layout(template=\"plotly_white\", showlegend=True)\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "        # Layout with two columns\n",
    "        col1, col2 = st.columns(2)\n",
    "    \n",
    "        # Column 1: Tables\n",
    "        table_to_show = (\n",
    "            test_partition_metrics\n",
    "            .join(partition_weights.select(\"GROUP_IDENTIFIER_STRING\", \"PARTITION_WEIGHT\"), on=[\"GROUP_IDENTIFIER_STRING\"])\n",
    "            .with_column(\"WGHT_PCT\", F.col(\"PARTITION_WEIGHT\")*100)\n",
    "            .select(\"GROUP_IDENTIFIER_STRING\", \"MAPE\", \"MAE\", \"RMSE\", \"WGHT_PCT\")\n",
    "        )\n",
    "        with col1:\n",
    "            # Look at the best performing partitions\n",
    "            st.subheader(\"BEST Performing Partitions\")\n",
    "            st.dataframe(table_to_show.sort(F.abs(metric)))\n",
    "        with col2:\n",
    "            # Look at the worst performing partitions\n",
    "            st.subheader(\"WORST Performing Partitions\")\n",
    "            st.dataframe(table_to_show.sort(F.abs(metric).desc()))\n",
    "\n",
    "    else:\n",
    "        table_to_show = (\n",
    "            test_partition_metrics\n",
    "            .join(partition_weights.select(\"GROUP_IDENTIFIER_STRING\", \"PARTITION_WEIGHT\"), on=[\"GROUP_IDENTIFIER_STRING\"])\n",
    "            .with_column(\"WGHT_PCT\", F.col(\"PARTITION_WEIGHT\")*100)\n",
    "            .select(\"GROUP_IDENTIFIER_STRING\", \"MAPE\", \"MAE\", \"RMSE\", \"WGHT_PCT\")\n",
    "        )\n",
    "        \n",
    "        st.subheader(f\"Sorted by {metric}\")\n",
    "        st.dataframe(table_to_show.sort(metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345df61d-96ed-4272-a298-e20d61acf0de",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "_partition_plots"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Visualize individual partition actual vs pred on a time series line chart\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Enter partition manually instead of using selectbox\n",
    "partition_input = st.text_input(\"Enter Partition Name\", key=\"partition_selector_1\")\n",
    "load_partition = st.button(\"Load Partition\")\n",
    "\n",
    "if load_partition and partition_input.strip():\n",
    "    partition_choice = partition_input.strip()\n",
    "\n",
    "    # Create a pandas dataframe\n",
    "    partition_choice_df = (\n",
    "        pred_v_actuals.filter(F.col(\"GROUP_IDENTIFIER_STRING\") == partition_choice)\n",
    "        .sort(TIME_PERIOD_COLUMN)\n",
    "        .to_pandas()\n",
    "    )\n",
    "    partition_choice_df[TIME_PERIOD_COLUMN] = pd.to_datetime(partition_choice_df[TIME_PERIOD_COLUMN])\n",
    "\n",
    "    tabs = st.tabs(\n",
    "        [\n",
    "            \"Line Plot: Validation Actual & Predicted\",\n",
    "            \"Scatter Plot: Validation Actual vs. Predicted\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # --- EDITED CODE FOR LINE PLOT ---\n",
    "    # Create a Plotly line chart\n",
    "    fig_line = px.line(\n",
    "        partition_choice_df,\n",
    "        x=TIME_PERIOD_COLUMN,\n",
    "        y=[TARGET_COLUMN, \"PREDICTED\"],\n",
    "        title=\"Validation Actual vs. Predicted\"\n",
    "    )\n",
    "\n",
    "    split_date = partition_choice_df[\n",
    "        partition_choice_df[\"DATASET\"]==\"TRAIN\"\n",
    "    ][TIME_PERIOD_COLUMN].max()\n",
    "\n",
    "    # Add a dashed vertical line at the specified date\n",
    "    fig_line.add_vline(\n",
    "        x=split_date.timestamp() * 1000,\n",
    "        line_dash=\"dash\",\n",
    "        line_color=\"red\",\n",
    "        annotation_text=\"Forecast Start\",\n",
    "        annotation_position=\"top left\"\n",
    "    )\n",
    "\n",
    "    # Render the Plotly figure in Streamlit\n",
    "    tabs[0].plotly_chart(fig_line, use_container_width=True)\n",
    "   \n",
    "    # ----------------------\n",
    "    # Validation Actuals vs. Predictions Scatter Plot\n",
    "    fig_scatter = px.scatter(\n",
    "        partition_choice_df,\n",
    "        x=TARGET_COLUMN,\n",
    "        y=\"PREDICTED\",\n",
    "        title=\"Predicted vs. Actual\",\n",
    "        opacity=0.6,\n",
    "        trendline=\"ols\",\n",
    "        hover_data=[\"PREDICTED\", TARGET_COLUMN, TIME_PERIOD_COLUMN],\n",
    "    )\n",
    "\n",
    "    # Add expected trendline (y = x)\n",
    "    min_visits = min(partition_choice_df[TARGET_COLUMN])\n",
    "    max_visits = max(partition_choice_df[TARGET_COLUMN])\n",
    "\n",
    "    fig_scatter.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[min_visits, max_visits],\n",
    "            y=[min_visits, max_visits],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=\"black\", dash=\"dash\"),\n",
    "            name=\"Expected Trend (y = x)\",\n",
    "            showlegend=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    tabs[1].plotly_chart(fig_scatter, use_container_width=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f597411c-0adb-4298-a4f9-4fb4c78c1db0",
   "metadata": {
    "collapsed": false,
    "name": "md_feature_importance"
   },
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ecdf96-13a7-4646-8a61-616cd64f9f19",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "_get_feature_importance"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances are from model version YOUNG_LEECH_2 in table MODEL_STORAGE_TEST_MODEL_1.\n"
     ]
    }
   ],
   "source": [
    "# Load model feature important data depending on use of model context or storage table\n",
    "\n",
    "if USE_CONTEXT:\n",
    "    model_obj = mv.load(force=True).context.model_refs\n",
    "    model_data = [(\n",
    "        part, \n",
    "        dict(feature_importance=dict(\n",
    "            zip(ref.model.feature_names_in_, [float(val) for val in ref.model.feature_importances_])\n",
    "        ))\n",
    "    ) for part,ref in model_obj.items()]\n",
    "\n",
    "    model_df = pd.DataFrame(model_data,columns=[\"GROUP_IDENTIFIER_STRING\",\"METADATA\"])\n",
    "    model_df[\"MODEL_NAME\"] = MODEL_NAME\n",
    "    print(\n",
    "        f\"Feature Importances are from model version {model_version_nm} model context.\"\n",
    "    )\n",
    "else:\n",
    "    models_sdf = (\n",
    "        session.table(f\"{MODEL_BINARY_STORAGE_TBL_NM}\")\n",
    "        .filter(F.col(\"MODEL_NAME\") == MODEL_NAME)\n",
    "        .filter(\n",
    "            F.col(\"MODEL_VERSION\")\n",
    "            == reg.get_model(qualified_model_name).default.version_name\n",
    "        )\n",
    "    )\n",
    "    model_df = models_sdf.select(\n",
    "        \"MODEL_NAME\", \"GROUP_IDENTIFIER_STRING\", \"METADATA\"\n",
    "    ).to_pandas()\n",
    "    print(\n",
    "        f\"Feature Importances are for model version {reg.get_model(qualified_model_name).default.version_name} in table {MODEL_BINARY_STORAGE_TBL_NM}.\"\n",
    "    )\n",
    "\n",
    "# Filter models to given lead if using direct multistep modeling\n",
    "if LEAD > 0:\n",
    "    model_df = model_df[\n",
    "        model_df[\"GROUP_IDENTIFIER_STRING\"].str.endswith(f\"LEAD_{LEAD}\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a97be1-2646-4304-8a5b-55b77c13ab9d",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "_plot_feature_importance"
   },
   "outputs": [],
   "source": [
    "def preprocess_model_data(df):\n",
    "    \"\"\"Preprocess model data by extracting feature importance from the METADATA column.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Extracts the \"feature_importance\" dictionary from the \"METADATA\" column.\n",
    "    2. Converts the extracted feature importance data into a new DataFrame where each row\n",
    "       represents a feature and its corresponding importance for a specific model.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame containing model data with at least\n",
    "                           the columns \"MODEL_NAME\", \"GROUP_IDENTIFIER_STRING\",\n",
    "                           and \"METADATA\".\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - pd.DataFrame: The original DataFrame with an additional \"FEATURE_IMPORTANCE\" column.\n",
    "            - pd.DataFrame: A new DataFrame containing the extracted features and their importance,\n",
    "              with columns [\"MODEL_NAME\", \"GROUP_IDENTIFIER_STRING\", \"FEATURE\", \"IMPORTANCE\"].\n",
    "\n",
    "    \"\"\"\n",
    "    # Extract feature importance from METADATA\n",
    "    df[\"FEATURE_IMPORTANCE\"] = df[\"METADATA\"].apply(\n",
    "        lambda x: (\n",
    "            json.loads(x).get(\"feature_importance\", {})\n",
    "            if isinstance(x, str)\n",
    "            else x.get(\"feature_importance\", {})\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Explode feature importance into rows\n",
    "    feature_rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        for feature, importance in row[\"FEATURE_IMPORTANCE\"].items():\n",
    "            feature_rows.append(\n",
    "                {\n",
    "                    \"MODEL_NAME\": row[\"MODEL_NAME\"],\n",
    "                    \"GROUP_IDENTIFIER_STRING\": row[\"GROUP_IDENTIFIER_STRING\"],\n",
    "                    \"FEATURE\": feature,\n",
    "                    \"IMPORTANCE\": importance,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    feature_df = pd.DataFrame(feature_rows)\n",
    "    return df, feature_df\n",
    "\n",
    "\n",
    "def calculate_average_rank(feature_df):\n",
    "    \"\"\"Calculate the average rank and importance of features across different group partitions.\n",
    "\n",
    "    This function:\n",
    "    1. Computes the rank of each feature within its \"GROUP_IDENTIFIER_STRING\" based on\n",
    "       feature importance in descending order.\n",
    "    2. Aggregates the average rank and average importance for each feature across all groups.\n",
    "    3. Returns the feature DataFrame with calculated ranks and a summarized DataFrame\n",
    "       sorted by average rank.\n",
    "\n",
    "    Args:\n",
    "        feature_df (pd.DataFrame): Input DataFrame containing extracted feature importance\n",
    "                                   with at least the columns [\"GROUP_IDENTIFIER_STRING\",\n",
    "                                   \"FEATURE\", \"IMPORTANCE\"].\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - pd.DataFrame: The input DataFrame with an additional \"RANK\" column.\n",
    "            - pd.DataFrame: A new DataFrame containing features and their average rank and\n",
    "              importance, with columns [\"FEATURE\", \"AVERAGE_RANK\", \"AVERAGE_IMPORTANCE\"].\n",
    "\n",
    "    \"\"\"\n",
    "    feature_df = feature_df.copy()\n",
    "    feature_df.loc[:, \"RANK\"] = feature_df.groupby(\"GROUP_IDENTIFIER_STRING\")[\n",
    "        \"IMPORTANCE\"\n",
    "    ].rank(ascending=False)\n",
    "\n",
    "    avg_rank_df = (\n",
    "        feature_df.groupby(\"FEATURE\")\n",
    "        .agg({\"RANK\": \"mean\", \"IMPORTANCE\": \"mean\"})\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    avg_rank_df.rename(\n",
    "        columns={\"RANK\": \"AVERAGE_RANK\", \"IMPORTANCE\": \"AVERAGE_IMPORTANCE\"},\n",
    "        inplace=True,\n",
    "    )\n",
    "    avg_rank_df = avg_rank_df.sort_values(\"AVERAGE_RANK\", ascending=True)\n",
    "    return feature_df, avg_rank_df\n",
    "\n",
    "\n",
    "def plot_feature_importance(df, is_aggregated=True, top_n=20):\n",
    "    \"\"\"Create a horizontal bar plot to visualize feature importance.\n",
    "\n",
    "    This function generates a feature importance plot based on whether the data\n",
    "    is aggregated (showing average ranks across groups) or unaggregated (showing\n",
    "    importance for a selected partition).\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing feature importance data.\n",
    "                           Expected columns:\n",
    "                           - If `is_aggregated=True`: [\"FEATURE\", \"AVERAGE_RANK\"]\n",
    "                           - If `is_aggregated=False`: [\"FEATURE\", \"IMPORTANCE\"]\n",
    "        is_aggregated (bool, optional): If True, plots average rank of features\n",
    "                                        across groups. If False, plots raw importance\n",
    "                                        for a single partition. Default is True.\n",
    "        top_n (int, optional): Number of top features to display in the plot.\n",
    "                               Default is 20.\n",
    "\n",
    "    Returns:\n",
    "        plotly.graph_objects.Figure: A bar plot visualizing the top feature importance.\n",
    "\n",
    "    \"\"\"\n",
    "    if is_aggregated:\n",
    "        df = df.sort_values(\"AVERAGE_RANK\", ascending=True).head(top_n)\n",
    "        x_col = \"AVERAGE_RANK\"\n",
    "        title = \"Top Feature Importance (Aggregated by Average Rank)\"\n",
    "        fig = px.bar(\n",
    "            df,\n",
    "            x=x_col,\n",
    "            y=\"FEATURE\",\n",
    "            orientation=\"h\",\n",
    "            title=title,\n",
    "            labels={\"FEATURE\": \"Feature\", x_col: \"Average Rank\"},\n",
    "        )\n",
    "\n",
    "        fig.update_layout(\n",
    "            yaxis=dict(categoryorder=\"total descending\"),\n",
    "            xaxis_title=\"Average Rank\",\n",
    "            yaxis_title=\"Feature\",\n",
    "            margin=dict(l=50, r=50, t=50, b=50),\n",
    "        )\n",
    "    else:\n",
    "        df = df.sort_values(\"IMPORTANCE\", ascending=False).head(top_n)\n",
    "        x_col = \"IMPORTANCE\"\n",
    "        title = \"Top Feature Importance for Selected Partition\"\n",
    "\n",
    "        fig = px.bar(\n",
    "            df,\n",
    "            x=x_col,\n",
    "            y=\"FEATURE\",\n",
    "            orientation=\"h\",\n",
    "            title=title,\n",
    "            labels={\"FEATURE\": \"Feature\", x_col: \"Importance\"},\n",
    "        )\n",
    "\n",
    "        fig.update_layout(\n",
    "            yaxis=dict(categoryorder=\"total ascending\"),\n",
    "            xaxis_title=\"Importance\",\n",
    "            yaxis_title=\"Feature\",\n",
    "            margin=dict(l=50, r=50, t=50, b=50),\n",
    "        )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Load and preprocess the data\n",
    "model_df, feature_df = preprocess_model_data(model_df)\n",
    "\n",
    "# Select Partition Model ID\n",
    "partition_models = model_df[\"GROUP_IDENTIFIER_STRING\"].unique()\n",
    "selected_partition_model = st.selectbox(\n",
    "    \"Select Partition\", [None] + sorted(partition_models)\n",
    ")\n",
    "\n",
    "# Filter data based on selections\n",
    "filtered_feature_df = feature_df\n",
    "if selected_partition_model:\n",
    "    filtered_feature_df = filtered_feature_df[\n",
    "        filtered_feature_df[\"GROUP_IDENTIFIER_STRING\"] == selected_partition_model\n",
    "    ]\n",
    "\n",
    "# Select Top N Features\n",
    "top_n = st.slider(\"Number of Top Features to Show\", min_value=5, max_value=50, value=20)\n",
    "\n",
    "\n",
    "# Display Feature Importance\n",
    "st.subheader(\"Feature Importance\")\n",
    "\n",
    "if selected_partition_model:\n",
    "    fig = plot_feature_importance(filtered_feature_df, is_aggregated=False, top_n=top_n)\n",
    "else:\n",
    "    filtered_feature_df, avg_rank_df = calculate_average_rank(filtered_feature_df)\n",
    "    fig = plot_feature_importance(avg_rank_df, is_aggregated=True, top_n=top_n)\n",
    "\n",
    "st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "# Expander for Underlying Data\n",
    "with st.expander(\"Show Underlying Data\"):\n",
    "    if selected_partition_model:\n",
    "        st.dataframe(filtered_feature_df.sort_values(\"IMPORTANCE\", ascending=False))\n",
    "    else:\n",
    "        tabs = st.tabs([\"Average Importance\", \"Individual Importance\"])\n",
    "        tabs[0].dataframe(avg_rank_df.sort_values(\"AVERAGE_RANK\", ascending=True))\n",
    "        tabs[1].dataframe(\n",
    "            filtered_feature_df.sort_values(\"IMPORTANCE\", ascending=False)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdf424e-e4c8-483e-b0e5-0dd004010c2f",
   "metadata": {
    "name": "md_model_promotion",
    "collapsed": false
   },
   "source": "# Promote Model Version?\n\nIf set to True, model version evaluated in this notebook will be promoted to default and a new inference table will be created from the test data. A model monitor to track future inference results will also be created."
  },
  {
   "cell_type": "code",
   "id": "c6a7f372-46c8-48bc-95c1-bc9863660158",
   "metadata": {
    "language": "python",
    "name": "_set_decision_value"
   },
   "outputs": [],
   "source": "PROMOTE_MODEL_VERSION = False",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a24ad5f0-3e96-4550-9a45-889c0efba434",
   "metadata": {
    "language": "python",
    "name": "_promote_and_monitor",
    "codeCollapsed": true,
    "collapsed": false
   },
   "outputs": [],
   "source": "if PROMOTE_MODEL_VERSION:\n    m = reg.get_model(qualified_model_name)\n    m.default = model_version_nm\n    print(f\"Model version {model_version_nm} promoted.\")\n    session.use_schema(MODEL_SCHEMA)\n    source_name = f\"{INFERENCE_RESULT_TBL_NM}_{MODEL_NAME}_{model_version_nm}\"\n    base_name = source_name + \"_BASELINE\"\n    table_exist = session.sql(f\"SHOW TABLES LIKE '{source_name}';\").count() > 0\n    if table_exist:\n        table_data = session.table(source_name).select(TIME_PERIOD_COLUMN,\"GROUP_IDENTIFIER_STRING\")\n        data_to_save = test_pred_v_actuals.join(table_data, on = [TIME_PERIOD_COLUMN, \"GROUP_IDENTIFIER_STRING\"], how=\"leftanti\")\n        data_to_save.drop(\"DATASET\").write.save_as_table(source_name, mode=\"append\")\n    else:\n        test_pred_v_actuals.drop(\"DATASET\").write.save_as_table(source_name, mode=\"overwrite\")\n    session.sql(f\"\"\"\n        CREATE OR REPLACE MODEL MONITOR {MODEL_NAME}_{model_version_nm}_MONITOR\n        WITH\n            MODEL={MODEL_NAME}\n            VERSION={model_version_nm}\n            FUNCTION=predict\n            SOURCE={source_name}\n            TIMESTAMP_COLUMN={TIME_PERIOD_COLUMN}\n            PREDICTION_SCORE_COLUMNS=(PREDICTED)  \n            ACTUAL_SCORE_COLUMNS=(MODEL_TARGET)\n            SEGMENT_COLUMNS = (GROUP_IDENTIFIER_STRING)\n            WAREHOUSE={SESSION_WH}\n            REFRESH_INTERVAL='1 day'\n            AGGREGATION_WINDOW='1 day';\n    \"\"\").collect()\n    print(\"Model monitor created\")",
   "execution_count": null
  }
 ]
}
