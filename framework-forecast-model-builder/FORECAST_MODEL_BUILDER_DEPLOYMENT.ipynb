{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ce110000-1111-2222-3333-ffffff000000",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "INTRODUCTION"
      },
      "source": [
        "# Forecast Model Builder Deployment\n",
        "\n",
        "This notebook deploys the Forecast Model Builder files to your Snowflake account. \n",
        "\n",
        "The Forecast Model Builder is a tool for efficiently building forecasts.  It includes a collection of notebooks (exploratory data analysis, modeling, and inference) and an orchestration layer for iterating on multiple projects."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce110000-1111-2222-3333-ffffff000001",
      "metadata": {
        "codeCollapsed": true,
        "name": "INSTRUCTIONS"
      },
      "source": [
        "# Instructions\n",
        "\n",
        "__Refer to the [README](https://github.com/Snowflake-Labs/emerging-solutions-toolbox/blob/main/framework-forecast-model-builder/README.md) for detailed instructions.__ \n",
        "\n",
        "NOTE: This notebook creates several Snowflake objects. It is recommending to use the default settings in following python cell, if the user has privileges to CREATE DB and WH. Users without those privileges who specify an __existing__ database and schema below, should follw the README instruction option that matches their privilege level. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce110000-1111-2222-3333-ffffff000002",
      "metadata": {
        "language": "python",
        "name": "_1_USER_CONSTANTS"
      },
      "outputs": [],
      "source": [
        "# -----------------------------------------------------------------------------------------\n",
        "# Solution constants\n",
        "# -----------------------------------------------------------------------------------------\n",
        "\n",
        "# Establish the name of the database and warehouse to be used for the solution\n",
        "# NOTE: User can specify an existing database and warehouse, or can specify a new database and warehouse to be created.\n",
        "# NOTE: If the following database and/or warehouse do not exist,\n",
        "#       this notebook will try to create them (assuming user's role has appropriate PRIVILEGES to create objects)\n",
        "SOLUTION_DB = \"FORECAST_MODEL_BUILDER\"\n",
        "DEPLOYMENT_WH = \"FORECAST_MODEL_BUILDER_WH\"\n",
        "\n",
        "# Establish the name of the schema that will be used to store the base objects (like staged files, stored procedures, etc)\n",
        "# NOTE: If SOLUTION_DB specified an already-existing db, then user must specify a schema that ALREADY EXISTS in that db.\n",
        "#       If SOLUTION_DB specified a new db to be created, then user must specify the name of a new schema that will be created in the db.\n",
        "SOLUTION_BASE_SCHEMA = \"BASE\"\n",
        "\n",
        "PROJECT_NAME = \"TEST_PROJECT\"\n",
        "\n",
        "# Git integration\n",
        "# If None, will attempt to create a git integration\n",
        "GIT_INTEGRATION = None\n",
        "\n",
        "# Establish the name of the stage to deploy the notebook templates into\n",
        "# NOTE: If SOLUTION_DB specified an already-existing db, then user must specify the name of a stage that ALREADY EXISTS in SOLUTION_BASE_SCHEMA.\n",
        "#       If SOLUTION_DB specified a new db to be created, then user must specify the name of a new stage that will be created in SOLUTION_BASE_SCHEMA.\n",
        "DEPLOYMENT_STAGE = \"DATA_STAGE\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07f73c6d-73f5-4664-bcef-3a233951ab25",
      "metadata": {
        "codeCollapsed": false,
        "collapsed": false,
        "language": "python",
        "name": "_2_DEPLOYMENT"
      },
      "outputs": [],
      "source": [
        "# Deploys the solution.  Creates a database if it doesn't yet\n",
        "# exist, and adds supporting schemas and stages, a default warehouse, and\n",
        "# will add a git repository to automatically load files.\n",
        "# Will check for needed permissions and will notify if missing.\n",
        "# *Note* - the role running the notebook will own the objects.\n",
        "\n",
        "# Import python packages\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "import pandas as pd\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "from snowflake.snowpark.functions import col\n",
        "\n",
        "session = get_active_session()\n",
        "\n",
        "# Solution constant to specify which framework directory to deploy from the Emerging Solutions Toolbox\n",
        "TOOLBOX_FOLDER_NAME = \"framework-forecast-model-builder\"\n",
        "\n",
        "# Permission variables\n",
        "can_create_db = False\n",
        "can_create_wh = False\n",
        "can_create_integration = False\n",
        "\n",
        "# Deployment variables\n",
        "database_deployed = False\n",
        "warehouse_deployed = False\n",
        "files_deployed = False\n",
        "zip_deployed = False\n",
        "git_repository_deployed = False\n",
        "confirm_message_sent = False\n",
        "\n",
        "\n",
        "# Checks the permissions of the current role\n",
        "def check_permissions(session):\n",
        "    global can_create_db\n",
        "    global can_create_wh\n",
        "    global can_create_integration\n",
        "\n",
        "    # Checks permissions of current role\n",
        "    current_role_sql = \"\"\"SELECT CURRENT_ROLE()\"\"\"\n",
        "\n",
        "    current_role = session.sql(current_role_sql).collect()[0][0]\n",
        "\n",
        "    admin_role_list = [\"ACCOUNTADMIN\", \"SYSADMIN\"]\n",
        "\n",
        "    if current_role not in admin_role_list:\n",
        "        grants_sql = \"\"\"SHOW GRANTS ON ACCOUNT\"\"\"\n",
        "        grants_df = session.sql(grants_sql)\n",
        "\n",
        "        create_db_df = grants_df.filter(\n",
        "            (col('\"privilege\"') == \"CREATE DATABASE\")\n",
        "            & (col('\"grantee_name\"') == current_role)\n",
        "        )\n",
        "\n",
        "        if create_db_df.count() > 0:\n",
        "            can_create_db = True\n",
        "\n",
        "        create_wh_df = grants_df.filter(\n",
        "            (col('\"privilege\"') == \"CREATE WAREHOUSE\")\n",
        "            & (col('\"grantee_name\"') == current_role)\n",
        "        )\n",
        "\n",
        "        if create_wh_df.count() > 0:\n",
        "            can_create_wh = True\n",
        "\n",
        "        create_integration_df = grants_df.filter(\n",
        "            (col('\"privilege\"') == \"CREATE INTEGRATION\")\n",
        "            & (col('\"grantee_name\"') == current_role)\n",
        "        )\n",
        "\n",
        "        if create_integration_df.count() > 0:\n",
        "            can_create_integration = True\n",
        "\n",
        "    else:\n",
        "        can_create_db = True\n",
        "        can_create_wh = True\n",
        "        can_create_integration = True\n",
        "\n",
        "\n",
        "# Deploys the database and supporting objects\n",
        "def deploy_database(session):\n",
        "    global database_deployed\n",
        "\n",
        "    # Check if database exists\n",
        "    db_check_sql = f\"\"\"SHOW DATABASES LIKE '{SOLUTION_DB}'\"\"\"\n",
        "    db_check_df = session.sql(db_check_sql)\n",
        "\n",
        "    if db_check_df.count() == 0 and can_create_db:\n",
        "        try:\n",
        "            # Create a database for the toolkit\n",
        "            create_db_sql = f\"\"\"CREATE DATABASE IF NOT EXISTS {SOLUTION_DB}\n",
        "            COMMENT = '{{\"origin\":\"sf_sit\", \"name\":\"sit_forecasting\", \"version\":{{\"major\":1, \"minor\":0}}, \"attributes\":{{\"component\":\"deployment\"}}}}'\"\"\"\n",
        "\n",
        "            session.sql(create_db_sql).collect()\n",
        "        except Exception as e:\n",
        "            print(\n",
        "                f\"⚠️ {SOLUTION_DB} database not available and could not be created.  Please change your role or reach out to an admin.  Error: \"\n",
        "                + str(e)\n",
        "            )\n",
        "        finally:\n",
        "            # Remove the public schema (only during initial deployment)\n",
        "            remove_public_schema_sql = f\"\"\"DROP SCHEMA IF EXISTS {SOLUTION_DB}.PUBLIC\"\"\"\n",
        "\n",
        "            session.sql(remove_public_schema_sql).collect()\n",
        "\n",
        "            # Create a schema for the toolkit itself (other schemas will be created for each project)\n",
        "            create_base_schema_sql = f\"\"\"CREATE SCHEMA IF NOT EXISTS {SOLUTION_DB}.{SOLUTION_BASE_SCHEMA}\n",
        "        COMMENT = '{{\"origin\":\"sf_sit\", \"name\":\"sit_forecasting\", \"version\":{{\"major\":1, \"minor\":0}}, \"attributes\":{{\"component\":\"deployment\"}}}}'\"\"\"\n",
        "\n",
        "            session.sql(create_base_schema_sql).collect()\n",
        "\n",
        "            # Create a stage for the data\n",
        "            create_stage_sql = f\"\"\"CREATE STAGE IF NOT EXISTS {SOLUTION_DB}.{SOLUTION_BASE_SCHEMA}.{DEPLOYMENT_STAGE}\n",
        "        DIRECTORY = (ENABLE = TRUE)\n",
        "        COMMENT = '{{\"origin\":\"sf_sit\", \"name\":\"sit_forecasting\", \"version\":{{\"major\":1, \"minor\":0}}, \"attributes\":{{\"component\":\"deployment\"}}}}'\"\"\"\n",
        "\n",
        "            session.sql(create_stage_sql).collect()\n",
        "\n",
        "            database_deployed = True\n",
        "\n",
        "    elif db_check_df.count() == 0 and not can_create_db:\n",
        "        print(\n",
        "            f\"⚠️ {SOLUTION_DB} database not available and the current role does not have the CREATE DATBASE permission.  Please change your role or reach out to an admin.\"\n",
        "        )\n",
        "\n",
        "    elif db_check_df.count() == 1:\n",
        "        database_deployed = True\n",
        "\n",
        "\n",
        "# Deploys the warehouse\n",
        "def deploy_warehouse(session):\n",
        "    global warehouse_deployed\n",
        "\n",
        "    # Check if warehouse exists\n",
        "    wh_check_sql = f\"\"\"SHOW WAREHOUSES LIKE '{DEPLOYMENT_WH}'\"\"\"\n",
        "    wh_check_df = session.sql(wh_check_sql)\n",
        "\n",
        "    if wh_check_df.count() == 0 and can_create_wh:\n",
        "        # Create a warehouse for the toolkit\n",
        "        create_wh_sql = f\"\"\"CREATE WAREHOUSE IF NOT EXISTS {DEPLOYMENT_WH}\n",
        "    WITH WAREHOUSE_SIZE = 'XSMALL'\n",
        "    WAREHOUSE_TYPE = 'STANDARD'\n",
        "    AUTO_SUSPEND = 10\n",
        "    AUTO_RESUME = TRUE\n",
        "    INITIALLY_SUSPENDED = TRUE\n",
        "    COMMENT = '{{\"origin\":\"sf_sit\", \"name\":\"sit_forecasting\", \"version\":{{\"major\":1, \"minor\":0}}, \"attributes\":{{\"component\":\"deployment\"}}}}'\"\"\"\n",
        "\n",
        "        session.sql(create_wh_sql).collect()\n",
        "\n",
        "        warehouse_deployed = True\n",
        "\n",
        "    elif wh_check_df.count() == 0 and not can_create_wh:\n",
        "        print(\n",
        "            f\"ℹ️ {DEPLOYMENT_WH} warehouse not available, either use your own or rerun with a role with the CREATE WAREHOUSE permission.\"\n",
        "        )\n",
        "\n",
        "    elif wh_check_df.count() == 1:\n",
        "        warehouse_deployed = True\n",
        "\n",
        "\n",
        "# Checks if files in the stage IS missing\n",
        "def check_stage(session):\n",
        "    global files_deployed\n",
        "\n",
        "    # Check if files are missing\n",
        "    files_check_sql = f\"\"\"LS @{SOLUTION_DB}.{SOLUTION_BASE_SCHEMA}.{DEPLOYMENT_STAGE}/emerging-solutions-toolbox-main/\"\"\"\n",
        "    if session.sql(files_check_sql).count() > 0:\n",
        "        files_deployed = True\n",
        "\n",
        "\n",
        "# Deploys the git repository\n",
        "def deploy_api_integration(session):\n",
        "    global GIT_INTEGRATION\n",
        "    if database_deployed and not files_deployed:\n",
        "        check_git_repository(session)\n",
        "        check_for_zip(session)\n",
        "\n",
        "        if git_repository_deployed:\n",
        "            add_files_from_git(session)\n",
        "\n",
        "        elif zip_deployed:\n",
        "            add_files_from_zip(session)\n",
        "\n",
        "        else:\n",
        "            print(\n",
        "                f\"ℹ️ If you do not want to use git, you can manually upload the zip file from the repository to {SOLUTION_DB}.{SOLUTION_BASE_SCHEMA}.{DEPLOYMENT_STAGE} and rerun this cell.\"\n",
        "            )\n",
        "\n",
        "            if GIT_INTEGRATION:\n",
        "                deploy_git(session)\n",
        "            else:\n",
        "                if can_create_integration:\n",
        "                    api_integration_name = \"SNOWFLAKE_LABS_GIT_API_INTEGRATION\"  # Set API integration name here\n",
        "                    print(f\"Creating API Integration: {api_integration_name}\")\n",
        "                    api_integration_create_sql = f\"\"\"CREATE OR REPLACE API INTEGRATION {api_integration_name}\n",
        "        API_PROVIDER = git_https_api\n",
        "        API_ALLOWED_PREFIXES = ('https://github.com/Snowflake-Labs/')\n",
        "        ENABLED = TRUE;\"\"\"\n",
        "                    session.sql(api_integration_create_sql).collect()\n",
        "                    GIT_INTEGRATION = api_integration_name\n",
        "                    deploy_git(session)\n",
        "\n",
        "                else:\n",
        "                    print(\n",
        "                        \"⚠️ There are no API integrations and the current role does not have permission to create one or contact your admin or manually stage the files and rerun this cell.\"\n",
        "                    )\n",
        "                \n",
        "    elif database_deployed and files_deployed:\n",
        "        # Check if git is added for status\n",
        "        check_git_repository(session)\n",
        "        check_for_zip(session)\n",
        "\n",
        "\n",
        "# Adds a git repository to the database\n",
        "def deploy_git(session):\n",
        "    global files_deployed\n",
        "    global confirm_message_sent\n",
        "    global git_repository_deployed\n",
        "\n",
        "    if GIT_INTEGRATION:\n",
        "        print(f\"Using API Integration: {GIT_INTEGRATION}\")\n",
        "        \n",
        "        try:\n",
        "            repo_sql = f\"\"\"CREATE GIT REPOSITORY IF NOT EXISTS {SOLUTION_DB}.{SOLUTION_BASE_SCHEMA}.EMERGING_SOLUTIONS_TOOLBOX\n",
        "API_INTEGRATION = \"{GIT_INTEGRATION}\"\n",
        "ORIGIN = 'https://github.com/Snowflake-Labs/emerging-solutions-toolbox.git'\"\"\"\n",
        "\n",
        "            session.sql(repo_sql).collect()\n",
        "            add_files_from_git(session)\n",
        "            git_repository_deployed = True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\n",
        "                \"⚠️ Could not create repository.  Try another API Integration or contact an admin.\\n  Error: \"\n",
        "                + str(e)\n",
        "            )\n",
        "    else:\n",
        "        print(\"⚠️ No git API integrations available. Please create one or contact your admin.\")\n",
        "\n",
        "    confirmation_message()\n",
        "\n",
        "\n",
        "# Writes a confirmation message if not already written\n",
        "def confirmation_message():\n",
        "    global confirm_message_sent\n",
        "\n",
        "    if database_deployed and files_deployed:\n",
        "        if not confirm_message_sent:\n",
        "            status_df = pd.DataFrame(\n",
        "                [\n",
        "                    [\"Database Deployed\", database_deployed],\n",
        "                    [\"Warehouse Deployed\", warehouse_deployed],\n",
        "                    [\n",
        "                        \"Git Repository or Zip Deployed\",\n",
        "                        git_repository_deployed or zip_deployed,\n",
        "                    ],\n",
        "                    [\"Files Deployed\", files_deployed],\n",
        "                ],\n",
        "                columns=[\"Step\", \"Complete\"],\n",
        "            )\n",
        "\n",
        "            display(status_df)\n",
        "\n",
        "            print(\n",
        "                \"✓ Solution from \" + str(TOOLBOX_FOLDER_NAME) + \" fully deployed!\"\n",
        "            )\n",
        "            confirm_message_sent = True\n",
        "\n",
        "\n",
        "# Checks if the git repository has been added\n",
        "def check_git_repository(session):\n",
        "    global git_repository_deployed\n",
        "\n",
        "    # Check for git repository\n",
        "    git_repository_sql = f\"\"\"SHOW GIT REPOSITORIES LIKE 'EMERGING_SOLUTIONS_TOOLBOX' IN DATABASE {SOLUTION_DB}\"\"\"\n",
        "    git_repository_df = session.sql(git_repository_sql)\n",
        "\n",
        "    if git_repository_df.count() > 0:\n",
        "        git_repository_deployed = True\n",
        "\n",
        "\n",
        "# Checks if the zip file has been uploaded\n",
        "def check_for_zip(session):\n",
        "    global zip_deployed\n",
        "\n",
        "    # Check for zip file\n",
        "    zip_check_sql = f\"\"\"LS @{SOLUTION_DB}.{SOLUTION_BASE_SCHEMA}.{DEPLOYMENT_STAGE} PATTERN='.*emerging-solutions-toolbox-main.zip'\"\"\"\n",
        "    zip_check_df = session.sql(zip_check_sql)\n",
        "\n",
        "    if zip_check_df.count() > 0:\n",
        "        zip_deployed = True\n",
        "\n",
        "\n",
        "# Adds the notebooks and python files to the stage from the git repository\n",
        "def add_files_from_git(session):\n",
        "    global files_deployed\n",
        "\n",
        "    if not files_deployed:\n",
        "        copy_notebooks_sql = f\"\"\"COPY FILES\n",
        "INTO @{SOLUTION_DB}.{SOLUTION_BASE_SCHEMA}.{DEPLOYMENT_STAGE}/emerging-solutions-toolbox-main/\n",
        "FROM @{SOLUTION_DB}.{SOLUTION_BASE_SCHEMA}.EMERGING_SOLUTIONS_TOOLBOX/branches/main/\"\"\"\n",
        "\n",
        "        session.sql(copy_notebooks_sql).collect()\n",
        "        files_deployed = True\n",
        "\n",
        "\n",
        "# Adds the notebooks and python files to the stage from a zip file\n",
        "def add_files_from_zip(session):\n",
        "    global files_deployed\n",
        "\n",
        "    if not files_deployed:\n",
        "        f = session.file.get_stream(\n",
        "            f\"@{SOLUTION_DB}.{SOLUTION_BASE_SCHEMA}.{DEPLOYMENT_STAGE}/emerging-solutions-toolbox-main.zip\"\n",
        "        )\n",
        "        with zipfile.ZipFile(f, \"r\") as git_zip:\n",
        "            git_zip.extractall()\n",
        "\n",
        "        dirname = [f for f in os.listdir('.') if f.startswith(\"emerging-solutions-toolbox\")][0]\n",
        "        os.rename(dirname, \"emerging-solutions-toolbox-main\")\n",
        "\n",
        "        path_list = [\n",
        "            os.path.join(dirpath, f)\n",
        "            for (dirpath, dirnames, filenames) in os.walk(\n",
        "                \"emerging-solutions-toolbox-main\"\n",
        "            )\n",
        "            for f in filenames\n",
        "        ]\n",
        "\n",
        "        for path in path_list:\n",
        "            directory, file_name = os.path.split(path)\n",
        "\n",
        "            put_result = session.file.put(\n",
        "                path,\n",
        "                f\"@{SOLUTION_DB}.{SOLUTION_BASE_SCHEMA}.{DEPLOYMENT_STAGE}/{directory}\",\n",
        "                auto_compress=False,\n",
        "            )\n",
        "\n",
        "        files_deployed = True\n",
        "\n",
        "\n",
        "# Deploys code specific for the solution\n",
        "def deploy_solution_specific_code(session):\n",
        "    if files_deployed:\n",
        "        # Deploy sample data\n",
        "        sample_data_deployed = False\n",
        "\n",
        "        sample_data_check_sql = f\"\"\"SHOW TABLES LIKE 'DAILY_PARTITIONED_SAMPLE_DATA' IN SCHEMA {SOLUTION_DB}.{SOLUTION_BASE_SCHEMA}\"\"\"\n",
        "        if session.sql(sample_data_check_sql).count() > 0:\n",
        "            sample_data_deployed = True\n",
        "\n",
        "        if not sample_data_deployed:\n",
        "            create_file_format_sql = f\"\"\"CREATE OR REPLACE FILE FORMAT {SOLUTION_DB}.{SOLUTION_BASE_SCHEMA}.CSV_FORMAT \n",
        "        TYPE = CSV\n",
        "        FIELD_DELIMITER = ','\n",
        "        PARSE_HEADER = TRUE\n",
        "        COMMENT = '{{\"origin\":\"sf_sit\", \"name\":\"sit_forecasting\", \"version\":{{\"major\":1, \"minor\":0}}, \"attributes\":{{\"component\":\"deployment\"}}}}'\"\"\"\n",
        "\n",
        "            session.sql(create_file_format_sql).collect()\n",
        "\n",
        "            create_table_sql = f\"\"\"CREATE OR REPLACE TABLE {SOLUTION_DB}.{SOLUTION_BASE_SCHEMA}.DAILY_PARTITIONED_SAMPLE_DATA USING TEMPLATE (\n",
        "    SELECT ARRAY_AGG(OBJECT_CONSTRUCT(*)) \n",
        "     FROM TABLE (INFER_SCHEMA(\n",
        "     LOCATION=>'@{SOLUTION_DB}.{SOLUTION_BASE_SCHEMA}.{DEPLOYMENT_STAGE}/emerging-solutions-toolbox-main/{TOOLBOX_FOLDER_NAME}/sample_data/daily_partitioned_sample_data.csv',\n",
        "     FILE_FORMAT=>'{SOLUTION_DB}.{SOLUTION_BASE_SCHEMA}.CSV_FORMAT')))\"\"\"\n",
        "            session.sql(create_table_sql).collect()\n",
        "\n",
        "            tag_table_sql = f\"\"\"ALTER TABLE {SOLUTION_DB}.{SOLUTION_BASE_SCHEMA}.DAILY_PARTITIONED_SAMPLE_DATA SET COMMENT = '{{\"origin\":\"sf_sit\", \"name\":\"sit_forecasting\", \"version\":{{\"major\":1, \"minor\":0}}, \"attributes\":{{\"component\":\"deployment\"}}}}'\"\"\"\n",
        "\n",
        "            session.sql(tag_table_sql).collect()\n",
        "\n",
        "            load_table_sql = f\"\"\"COPY INTO {SOLUTION_DB}.{SOLUTION_BASE_SCHEMA}.DAILY_PARTITIONED_SAMPLE_DATA\n",
        "    from '@{SOLUTION_DB}.{SOLUTION_BASE_SCHEMA}.{DEPLOYMENT_STAGE}/emerging-solutions-toolbox-main/{TOOLBOX_FOLDER_NAME}/sample_data/daily_partitioned_sample_data.csv'\n",
        "    FILE_FORMAT = (SKIP_HEADER = 1)\"\"\"\n",
        "\n",
        "            session.sql(load_table_sql).collect()\n",
        "\n",
        "    create_schema_sql = f\"\"\"CREATE SCHEMA IF NOT EXISTS {SOLUTION_DB}.{PROJECT_NAME}\n",
        "    COMMENT = '{{{{\"origin\":\"sf_sit\", \"name\":\"sit_forecasting\", \"version\":{{{{\"major\":1, \"minor\":0}}}}, \"attributes\":{{{{\"component\":\"deployment\"}}}}}}}}'\"\"\"\n",
        "\n",
        "    session.sql(create_schema_sql).collect()\n",
        "\n",
        "    return f\"\"\"Project schema created. Use Git integration to manage notebooks in Workspaces.\"\"\"\n",
        "\n",
        "\n",
        "check_permissions(session)\n",
        "deploy_database(session)\n",
        "deploy_warehouse(session)\n",
        "check_stage(session)\n",
        "deploy_api_integration(session)\n",
        "deploy_solution_specific_code(session)\n",
        "confirmation_message()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f535428-5e4f-4b3a-96e0-082a040e855b",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false,
        "name": "NEXT_STEPS"
      },
      "source": [
        "**Next Steps**\n",
        "\n",
        "Once you've created your project, go to your Notebooks and start with <your project name>__EDA"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "forecast",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.11"
    },
    "lastEditStatus": {
      "authorEmail": "allie.feras@snowflake.com",
      "authorId": "8790037420708",
      "authorName": "AFERAS",
      "lastEditTime": 1766509390763,
      "notebookId": "uktfdym7yj635fbedud7",
      "sessionId": "09227e21-3329-4235-a4c3-357a71cd3ca6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
